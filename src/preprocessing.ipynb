{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mark/src/books/src'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, csv, time\n",
    "import config\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create an empty CSV file with the colums to fill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_csv(filename):\n",
    "    csvfile = open(config.dataset_dir + 'output/{0}.csv'.format(filename), \"w\")\n",
    "    writer = csv.writer(csvfile)\n",
    "    columns = ['filename', 'title', 'author', 'release year', 'pos score', 'neg score', 'neu score', 'comp score']\n",
    "    writer.writerow(columns)\n",
    "\n",
    "create_empty_csv('tard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be able to extract the filename, title, author and release year from every book and save it to a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00053.txt', 'LOC Workshop on Electronic Texts', 'Library of Congress', 'February, 1993']\n",
      "['00054.txt', 'The Marvellous Land of Oz', 'L. Frank Baum', 'February, 1993']\n",
      "['00055.txt', 'The Wonderful Wizard of Oz', 'L. Frank Baum', 'July 1, 2008 ']\n",
      "['00056.txt', 'NREN for All: Insurmountable Opportunity', 'Jean Armour Polly', 'March, 1993']\n",
      "['00057.txt', 'Aladdin and the Magic Lamp', 'Unknown', 'June 12, 2008 ']\n",
      "['00058.txt', 'Paradise Regained', 'John Milton', 'June 20, 2008 ']\n",
      "['00059.txt', 'A Discourse on Method', 'Renï¿½ Descartes', 'July 1, 2008 ']\n",
      "['00060.txt', 'The Scarlet Pimpernel', 'Baroness Orczy', 'March 7, 2006 ']\n",
      "['556.txt', 'Rewards and Fairies', 'Rudyard Kipling', 'June, 1996 ']\n",
      "['557.txt', \"Puck of Pook's Hill\", 'Rudyard Kipling', 'June, 1996']\n",
      "['558.txt', 'The Thirty-nine Steps', 'John Buchan', 'June, 1996']\n",
      "['559.txt', 'Greenmantle', 'John Buchan', 'June, 1996']\n",
      "['560.txt', 'Mr. Standfast', 'John Buchan', 'June, 1996']\n",
      "['561.txt', 'The Further Adventures of Robinson Crusoe', 'Daniel Defoe', 'January 18, 2007  ']\n",
      "['562.txt', 'Go Ahead Boys and the Racing Motorboat', 'Ross Kay', 'June, 1996']\n",
      "['563.txt', 'The Planet Mars and its Inhabitants', 'Eros Urides and J. L. Kennon', 'September 27, 2008 ']\n",
      "['564.txt', 'The Mystery of Edwin Drood', 'Charles Dickens', 'December 25, 2010  ']\n",
      "['570.txt', 'The Moravians in Georgia', 'Adelaide L. Fries', 'June, 1996  ']\n"
     ]
    }
   ],
   "source": [
    "def obtain_data_from_books(directory):\n",
    "    \n",
    "    # initiate CSV file \n",
    "    csvfile = open(config.dataset_dir + 'output/tard.csv', \"a\")\n",
    "    writer = csv.writer(csvfile)\n",
    "  \n",
    "    for book in os.listdir(directory):\n",
    "        if not book.startswith(\".\"):\n",
    "            with open(directory + book, errors='replace') as f:\n",
    "                text = f.read().splitlines()\n",
    "        \n",
    "        author = \"NULL\"\n",
    "        title = \"NULL\"\n",
    "        release_date = \"NULL\"\n",
    "        \n",
    "        # for line in text, check if title, author or release date are stored there\n",
    "        for i in range(80):\n",
    "            # error handling since some texts are <80 lines\n",
    "            try:\n",
    "                if \"Title: \" in text[i]:\n",
    "                    title = text[i][7:]\n",
    "                if \"Author: \" in text[i]:\n",
    "                    author = text[i][8:]\n",
    "                if \"Release Date: \" in text[i]:\n",
    "                    release_date = text[i][14:].split('[')[0]\n",
    "                # if they have both been found, do not waste extra time iterating \n",
    "                if title != \"NULL\" and author != \"NULL\" and release_date != \"NULL\":\n",
    "                    title_author_rd_triple = (title, author, release_date)\n",
    "                    pass\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        data = [book, title, author, release_date]\n",
    "        if not 'NULL' in data:\n",
    "            writer.writerow(data)\n",
    "            print (data)\n",
    "\n",
    "    \n",
    "directory = config.dataset_dir + \"test/\"\n",
    "obtain_data_from_books(directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete header and legal stuff at the beginning and end of the books. Books from the gutenberg project have certain sentences that mark the start and the end of a book. This can be exploited to extract only the content from the books that is relevant to our research. The function below does this for all books in the given directory and puts the stripped books in a new directory. The unstripped books are kept because some useful information is found in the headers (author, title, release date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unwanted_text(directory, outputdir):\n",
    "\n",
    "    # lists with sentences that either mark the end or the beginning of a book\n",
    "    start_list = (\"*** START OF\", \"***START OF\")\n",
    "    stop_list = (\"*** END OF\", \"***END OF\", \"End of the Project\")\n",
    "\n",
    "    for book in os.listdir(directory):\n",
    "        print(book)\n",
    "        if not book.startswith(\".\"):\n",
    "            with open(directory + book, errors='replace') as f:\n",
    "                content = f.readlines()\n",
    "                \n",
    "            start_index = 1\n",
    "            stop_index = len(content) - 1\n",
    "        \n",
    "            for line in range(len(content)):\n",
    "        \n",
    "              if any(item in content[line] for item in start_list):\n",
    "                start_index = line + 1\n",
    "              #if stop1 or stop2 or stop3 in content[line]:\n",
    "              if any(item in content[line] for item in stop_list):\n",
    "                stop_index = line - 2\n",
    "            \n",
    "            book_content = content[start_index:stop_index]\n",
    "            outfile = open(outputdir + '/' + book, 'w')\n",
    "            outfile.writelines(book_content)\n",
    "            outfile.close()\n",
    "\n",
    "#     end_time = time.clock()\n",
    "#     total_time = end_time - start_time\n",
    "#     print (\"The total time: \", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "00052.txt\n",
      "00053.txt\n",
      "00054.txt\n",
      "00055.txt\n",
      "00056.txt\n",
      "00057.txt\n",
      "00058.txt\n",
      "00059.txt\n",
      "00060.txt\n",
      "556.txt\n",
      "557.txt\n",
      "558.txt\n",
      "559.txt\n",
      "560.txt\n",
      "561.txt\n",
      "562.txt\n",
      "563.txt\n",
      "564.txt\n",
      "570.txt\n"
     ]
    }
   ],
   "source": [
    "directory = config.dataset_dir + \"test/\"\n",
    "outputdir = config.dataset_dir + \"output/\"\n",
    "remove_unwanted_text(directory, outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
