{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mark/src/books/src'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, csv, time\n",
    "import pandas as pd\n",
    "import sparql\n",
    "from collections import Counter\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local modules\n",
    "import config\n",
    "import sparql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create an empty CSV file with the colums to fill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find additional info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup the data from the csv file to a pd dataframe and set the index of the dataframe to the titles of the books. The latter will be useful later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = config.dataset_dir + 'bookdata_alt.csv'\n",
    "info = pd.read_csv(filename)\n",
    "info.index = info['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, _ = sparql.book_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def books_info(title_list=[], verbose=False):\n",
    "    \n",
    "    print('searching %i titles' % len(title_list))\n",
    "    data_per_book = []\n",
    "    unknown_titles = []\n",
    "    current = 0\n",
    "    # keys, _ = sparql.book_info()\n",
    "    for title in title_list:\n",
    "        current +=1\n",
    "        # TODO try a couple of times\n",
    "        i = 3\n",
    "        success = 'pending'\n",
    "        while not success == 'ok' or i == 0:\n",
    "            i -= 1\n",
    "            # book info returns     \n",
    "            #  ('ok', (keys, [info_dict]) ) | ('error', 'http_error')\n",
    "            (success, result) = sparql.book_info(title)\n",
    "            if verbose: print(success, len(result[1]))\n",
    "            if success == 'ok':\n",
    "                _, results = result\n",
    "                if not results == []:\n",
    "                    # ignore all but the first result\n",
    "                    # TODO save results that have an author\n",
    "                    data_per_book.append(results[0])\n",
    "                else: # 'http_error'\n",
    "                    if verbose: print('error', title)\n",
    "                    unknown_titles.append(title)\n",
    "\n",
    "        if not success == 'ok':\n",
    "            unknown_titles.append(title)\n",
    "        \n",
    " \n",
    "    return data_per_book, unknown_titles\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function books_info to get the data for the books found in dbpedia and the books that where not found in dbpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching 1000 titles\n",
      "n results 121\n",
      "n failed (not found) 879\n"
     ]
    }
   ],
   "source": [
    "v = False\n",
    "results, unknown_titles = books_info(info['title'][:1000], verbose=v)\n",
    "\n",
    "print('n results',len(results))\n",
    "print('n failed (not found)',len(unknown_titles))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete rows from the dataframe where the book is not found in dbpedia. Without this data, the row is useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = 0\n",
    "for title in unknown_titles:\n",
    "    dropped += 1\n",
    "    print(dropped)\n",
    "    info = info.drop(title)\n",
    "    \n",
    "print('dropped %i books' % dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to find the genres for all books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_genres(dic):\n",
    "    to_strip = 'http://dbpedia.org/resource/'\n",
    "    genre_list = []\n",
    "    title_list = []\n",
    "   \n",
    "    for result in dic:\n",
    "        try:\n",
    "            genre = (result['genre']['value'])\n",
    "            genre = genre.replace(to_strip, '')\n",
    "            genre = genre.replace('_', ' ')\n",
    "            genre_list.append(genre)\n",
    "            \n",
    "        except KeyError as error:\n",
    "            genre = 'unknown'\n",
    "            genre_list.append(genre)\n",
    "            # Output expected KeyErrors.\n",
    "            continue\n",
    "            \n",
    "  \n",
    "    # COMMENTED CODE DOES NOT WORK YET  \n",
    "    genres = pd.Series(genre_list)\n",
    "    info['genre'] = genres.values\n",
    "    unique_genres = set(genre_list)\n",
    "    genre_distribution = Counter(genre_list)\n",
    "    print(len([genre for genre in genres if genre != \"unknown\"]))\n",
    "    return unique_genres, genre_distribution, info\n",
    "\n",
    "unique_genres, genre_distribution, info = find_genres(results)\n",
    "print(genre_distribution)\n",
    "info = info[info.genre != 'unknown']\n",
    "\n",
    "info.to_csv(config.dataset_dir + '/output/final_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a file that stores the unique genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_file = open(config.dataset_dir +'output/unique_genres.txt', 'w')\n",
    "for item in unique_genres:\n",
    "    genres_file.write('%s\\n' % item)\n",
    "\n",
    "genres_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sanitized = [sparql.sanitize(t) for t in unknown_titles]\n",
    "results, unknown_titles = books_info(sanitized, verbose=v)\n",
    "print('n results',len(results))\n",
    "print('n failed (not found)',len(unknown_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO string.strip\n",
    "import sparql\n",
    "string = \"sdf ' df\"\n",
    "# string = string.strip('\"')\n",
    "# string = string.strip(\"'\")\n",
    "sparql.sanitize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['title'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
