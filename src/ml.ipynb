{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, os, numpy as np, collections\n",
    "import os, sklearn, pandas, numpy as np\n",
    "from sklearn import svm\n",
    "import skimage\n",
    "from skimage import io, filters\n",
    "from utils import utils # custom functions, in local environment\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import TensorBoard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN libs\n",
    "import keras\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, Conv3D, MaxPool2D, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset :: namedtuple(\n",
      "  'info': pandas.df\n",
      "  'labels': pandas.df('filename.txt': 'genre')\n",
      "  'genres': ['genre'] # unique genres\n",
      "  'label_dataset': SubDataset\n",
      "  'sentiment_dataset': SubDataset\n",
      "  'book_sentiment_words_list': ['filename']\n",
      "\n",
      " SubDataset :: namedtuple(\n",
      "   'dict_index_to_label' = dict to convert label_index -> label_name\n",
      "   'dict_label_to_index'= dict to convert label_name -> label_index\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import data, config, tfidf, models\n",
    "from utils import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'filename', 'title.1', 'author', 'release year', 'genre',\n",
       "       'pos score', 'neg score', 'neu score', 'comp score', 'amt pos',\n",
       "       'amt neg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# info = pandas.read_csv(config.dataset_dir + 'final_data.csv')\n",
    "dataset = data.init_dataset()\n",
    "dataset.info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.book_sentiment_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "amt = 800\n",
    "train = dataset.book_sentiment_words_list[:amt]\n",
    "test = dataset.book_sentiment_words_list[amt:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = data.extract_all(dataset, train)\n",
    "x_test, y_test = data.extract_all(dataset, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1005.txt</th>\n",
       "      <th>1024.txt</th>\n",
       "      <th>1027.txt</th>\n",
       "      <th>103.txt</th>\n",
       "      <th>1051.txt</th>\n",
       "      <th>1056.txt</th>\n",
       "      <th>106.txt</th>\n",
       "      <th>1066-0.txt</th>\n",
       "      <th>1080.txt</th>\n",
       "      <th>1081.txt</th>\n",
       "      <th>...</th>\n",
       "      <th>9845-8.txt</th>\n",
       "      <th>9845.txt</th>\n",
       "      <th>9846-8.txt</th>\n",
       "      <th>9846.txt</th>\n",
       "      <th>9858-8.txt</th>\n",
       "      <th>9858.txt</th>\n",
       "      <th>9865-8.txt</th>\n",
       "      <th>9865.txt</th>\n",
       "      <th>9909.txt</th>\n",
       "      <th>996.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>christian</td>\n",
       "      <td>adventur</td>\n",
       "      <td>western</td>\n",
       "      <td>travel</td>\n",
       "      <td>comic</td>\n",
       "      <td>knstlerroman</td>\n",
       "      <td>adventur</td>\n",
       "      <td>children</td>\n",
       "      <td>satir</td>\n",
       "      <td>polit</td>\n",
       "      <td>...</td>\n",
       "      <td>spi</td>\n",
       "      <td>spi</td>\n",
       "      <td>fantasi</td>\n",
       "      <td>fantasi</td>\n",
       "      <td>poetri magazin</td>\n",
       "      <td>poetri magazin</td>\n",
       "      <td>world war ii</td>\n",
       "      <td>world war ii</td>\n",
       "      <td>gothic</td>\n",
       "      <td>novel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 744 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1005.txt  1024.txt 1027.txt 103.txt 1051.txt      1056.txt   106.txt  \\\n",
       "0  christian  adventur  western  travel    comic  knstlerroman  adventur   \n",
       "\n",
       "  1066-0.txt 1080.txt 1081.txt   ...   9845-8.txt 9845.txt 9846-8.txt  \\\n",
       "0   children    satir    polit   ...          spi      spi    fantasi   \n",
       "\n",
       "  9846.txt      9858-8.txt        9858.txt    9865-8.txt      9865.txt  \\\n",
       "0  fantasi  poetri magazin  poetri magazin  world war ii  world war ii   \n",
       "\n",
       "  9909.txt 996.txt  \n",
       "0   gothic   novel  \n",
       "\n",
       "[1 rows x 744 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>filename</th>\n",
       "      <th>title.1</th>\n",
       "      <th>author</th>\n",
       "      <th>release year</th>\n",
       "      <th>genre</th>\n",
       "      <th>pos score</th>\n",
       "      <th>neg score</th>\n",
       "      <th>neu score</th>\n",
       "      <th>comp score</th>\n",
       "      <th>amt pos</th>\n",
       "      <th>amt neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jonah</td>\n",
       "      <td>3678.txt</td>\n",
       "      <td>Jonah</td>\n",
       "      <td>Louis Stone</td>\n",
       "      <td>January, 2003</td>\n",
       "      <td>poetri</td>\n",
       "      <td>0.063752</td>\n",
       "      <td>0.064028</td>\n",
       "      <td>0.670289</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>2058</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>King--of the Khyber Rifles</td>\n",
       "      <td>6066.txt</td>\n",
       "      <td>King--of the Khyber Rifles</td>\n",
       "      <td>Talbot Mundy</td>\n",
       "      <td>July, 2004</td>\n",
       "      <td>adventur</td>\n",
       "      <td>0.056072</td>\n",
       "      <td>0.044295</td>\n",
       "      <td>0.660100</td>\n",
       "      <td>0.020974</td>\n",
       "      <td>2518</td>\n",
       "      <td>2115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Wind in the Willows</td>\n",
       "      <td>289.txt</td>\n",
       "      <td>The Wind in the Willows</td>\n",
       "      <td>Kenneth Grahame</td>\n",
       "      <td>July, 1995</td>\n",
       "      <td>children</td>\n",
       "      <td>0.075622</td>\n",
       "      <td>0.049711</td>\n",
       "      <td>0.708466</td>\n",
       "      <td>0.050425</td>\n",
       "      <td>1684</td>\n",
       "      <td>1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akbar</td>\n",
       "      <td>40155-8.txt</td>\n",
       "      <td>Akbar</td>\n",
       "      <td>P. A. S. van Limburg-Brouwer</td>\n",
       "      <td>July 7, 2012</td>\n",
       "      <td>syair</td>\n",
       "      <td>0.088927</td>\n",
       "      <td>0.047641</td>\n",
       "      <td>0.701412</td>\n",
       "      <td>0.078233</td>\n",
       "      <td>2988</td>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Erewhon</td>\n",
       "      <td>1906.txt</td>\n",
       "      <td>Erewhon</td>\n",
       "      <td>Samuel Butler</td>\n",
       "      <td>March 20, 2005</td>\n",
       "      <td>satir</td>\n",
       "      <td>0.075006</td>\n",
       "      <td>0.061587</td>\n",
       "      <td>0.750951</td>\n",
       "      <td>0.025886</td>\n",
       "      <td>2506</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Night and Day</td>\n",
       "      <td>1245.txt</td>\n",
       "      <td>Night and Day</td>\n",
       "      <td>Virginia Woolf</td>\n",
       "      <td>March, 1998</td>\n",
       "      <td>romance</td>\n",
       "      <td>0.070135</td>\n",
       "      <td>0.048907</td>\n",
       "      <td>0.711205</td>\n",
       "      <td>0.043948</td>\n",
       "      <td>4822</td>\n",
       "      <td>3088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>She and Allan</td>\n",
       "      <td>5745.txt</td>\n",
       "      <td>She and Allan</td>\n",
       "      <td>H. Rider Haggard</td>\n",
       "      <td>April 22, 2006</td>\n",
       "      <td>fantasi</td>\n",
       "      <td>0.067608</td>\n",
       "      <td>0.057010</td>\n",
       "      <td>0.693447</td>\n",
       "      <td>0.020357</td>\n",
       "      <td>3234</td>\n",
       "      <td>2652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Amateur Cracksman</td>\n",
       "      <td>706.txt</td>\n",
       "      <td>The Amateur Cracksman</td>\n",
       "      <td>E. W. Hornung</td>\n",
       "      <td>November, 1996</td>\n",
       "      <td>crime</td>\n",
       "      <td>0.059576</td>\n",
       "      <td>0.045972</td>\n",
       "      <td>0.663071</td>\n",
       "      <td>0.026517</td>\n",
       "      <td>1363</td>\n",
       "      <td>1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Anne of Geierstein</td>\n",
       "      <td>44247-8.txt</td>\n",
       "      <td>Anne of Geierstein</td>\n",
       "      <td>Walter Scott</td>\n",
       "      <td>November 21, 2013</td>\n",
       "      <td>histor</td>\n",
       "      <td>0.080691</td>\n",
       "      <td>0.054442</td>\n",
       "      <td>0.716062</td>\n",
       "      <td>0.048409</td>\n",
       "      <td>3268</td>\n",
       "      <td>2205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Tramp Abroad</td>\n",
       "      <td>5786.txt</td>\n",
       "      <td>A Tramp Abroad</td>\n",
       "      <td>Mark Twain (Samuel Clemens)</td>\n",
       "      <td>March 1994</td>\n",
       "      <td>travel</td>\n",
       "      <td>0.062378</td>\n",
       "      <td>0.037464</td>\n",
       "      <td>0.720202</td>\n",
       "      <td>0.047015</td>\n",
       "      <td>642</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Captives of the Flame</td>\n",
       "      <td>41905.txt</td>\n",
       "      <td>Captives of the Flame</td>\n",
       "      <td>Samuel R. Delany</td>\n",
       "      <td>January 24, 2013</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>0.037854</td>\n",
       "      <td>0.037340</td>\n",
       "      <td>0.663475</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>850</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Madame de Mauves</td>\n",
       "      <td>7813.txt</td>\n",
       "      <td>Madame de Mauves</td>\n",
       "      <td>Henry James</td>\n",
       "      <td>April, 2005</td>\n",
       "      <td>novella</td>\n",
       "      <td>0.098595</td>\n",
       "      <td>0.055954</td>\n",
       "      <td>0.732808</td>\n",
       "      <td>0.084604</td>\n",
       "      <td>1301</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Five Weeks in a Balloon</td>\n",
       "      <td>3526.txt</td>\n",
       "      <td>Five Weeks in a Balloon</td>\n",
       "      <td>Jules Verne</td>\n",
       "      <td>November, 2002</td>\n",
       "      <td>adventur</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>0.041392</td>\n",
       "      <td>0.660914</td>\n",
       "      <td>0.018097</td>\n",
       "      <td>2156</td>\n",
       "      <td>1643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tara</td>\n",
       "      <td>45430.txt</td>\n",
       "      <td>Tara</td>\n",
       "      <td>Philip Meadows Taylor</td>\n",
       "      <td>April 18, 2014</td>\n",
       "      <td>prose poetri</td>\n",
       "      <td>0.072001</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.696242</td>\n",
       "      <td>0.031076</td>\n",
       "      <td>6587</td>\n",
       "      <td>5509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Mysteries of Udolpho</td>\n",
       "      <td>3268.txt</td>\n",
       "      <td>The Mysteries of Udolpho</td>\n",
       "      <td>Ann Radcliffe</td>\n",
       "      <td>June, 2002</td>\n",
       "      <td>gothic</td>\n",
       "      <td>0.073049</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.734536</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>7454</td>\n",
       "      <td>7002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Notre-Dame de Paris</td>\n",
       "      <td>2610.txt</td>\n",
       "      <td>Notre-Dame de Paris</td>\n",
       "      <td>Victor Hugo</td>\n",
       "      <td>April, 2001</td>\n",
       "      <td>dystopia</td>\n",
       "      <td>0.057745</td>\n",
       "      <td>0.052302</td>\n",
       "      <td>0.675644</td>\n",
       "      <td>0.011826</td>\n",
       "      <td>4271</td>\n",
       "      <td>3857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Clocks</td>\n",
       "      <td>855.txt</td>\n",
       "      <td>Clocks</td>\n",
       "      <td>Jerome K. Jerome</td>\n",
       "      <td>March, 1997</td>\n",
       "      <td>drama</td>\n",
       "      <td>0.070207</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.673357</td>\n",
       "      <td>0.055263</td>\n",
       "      <td>218</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Green Eyes</td>\n",
       "      <td>45557-8.txt</td>\n",
       "      <td>Green Eyes</td>\n",
       "      <td>Roy J. Snell</td>\n",
       "      <td>May 1, 2014</td>\n",
       "      <td>young adult</td>\n",
       "      <td>0.052123</td>\n",
       "      <td>0.043438</td>\n",
       "      <td>0.606841</td>\n",
       "      <td>0.023032</td>\n",
       "      <td>972</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Botticelli</td>\n",
       "      <td>39942-8.txt</td>\n",
       "      <td>Botticelli</td>\n",
       "      <td>Henry Bryan Binns</td>\n",
       "      <td>June 7, 2012</td>\n",
       "      <td>mysteri</td>\n",
       "      <td>0.065328</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>0.714379</td>\n",
       "      <td>0.072371</td>\n",
       "      <td>317</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The Longest Journey</td>\n",
       "      <td>2604.txt</td>\n",
       "      <td>The Longest Journey</td>\n",
       "      <td>E. M. Forster</td>\n",
       "      <td>April, 2001</td>\n",
       "      <td>bildungsroman</td>\n",
       "      <td>0.066929</td>\n",
       "      <td>0.056150</td>\n",
       "      <td>0.652915</td>\n",
       "      <td>0.021845</td>\n",
       "      <td>2607</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Down and Out in the Magic Kingdom</td>\n",
       "      <td>8086-8.txt</td>\n",
       "      <td>Down and Out in the Magic Kingdom</td>\n",
       "      <td>Cory Doctorow</td>\n",
       "      <td>May, 2005</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>0.059361</td>\n",
       "      <td>0.044526</td>\n",
       "      <td>0.652722</td>\n",
       "      <td>0.026161</td>\n",
       "      <td>1322</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Meccania</td>\n",
       "      <td>44074.txt</td>\n",
       "      <td>Meccania</td>\n",
       "      <td>Owen Gregory</td>\n",
       "      <td>October 30, 2013</td>\n",
       "      <td>utopiananddystopian</td>\n",
       "      <td>0.069571</td>\n",
       "      <td>0.034635</td>\n",
       "      <td>0.739040</td>\n",
       "      <td>0.062762</td>\n",
       "      <td>2146</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Leinster</td>\n",
       "      <td>43096.txt</td>\n",
       "      <td>Leinster</td>\n",
       "      <td>Stephen Lucius Gwynn</td>\n",
       "      <td>July 5, 2013</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>0.076081</td>\n",
       "      <td>0.033165</td>\n",
       "      <td>0.747439</td>\n",
       "      <td>0.080475</td>\n",
       "      <td>509</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Off on a Comet</td>\n",
       "      <td>1353-8.txt</td>\n",
       "      <td>Off on a Comet</td>\n",
       "      <td>Jules Verne</td>\n",
       "      <td>June, 1998</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>0.058780</td>\n",
       "      <td>0.040971</td>\n",
       "      <td>0.698877</td>\n",
       "      <td>0.032333</td>\n",
       "      <td>2575</td>\n",
       "      <td>1785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The Ivory Trail</td>\n",
       "      <td>5194.txt</td>\n",
       "      <td>The Ivory Trail</td>\n",
       "      <td>Talbot Mundy</td>\n",
       "      <td>February, 2004</td>\n",
       "      <td>horror</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.054841</td>\n",
       "      <td>0.683443</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>3347</td>\n",
       "      <td>3419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sketches by Boz</td>\n",
       "      <td>882.txt</td>\n",
       "      <td>Sketches by Boz</td>\n",
       "      <td>Charles Dickens</td>\n",
       "      <td>December 6, 2009</td>\n",
       "      <td>sketch stori</td>\n",
       "      <td>0.078445</td>\n",
       "      <td>0.048444</td>\n",
       "      <td>0.724015</td>\n",
       "      <td>0.057092</td>\n",
       "      <td>7439</td>\n",
       "      <td>4611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hunger</td>\n",
       "      <td>8387-8.txt</td>\n",
       "      <td>Hunger</td>\n",
       "      <td>Knut Hamsun</td>\n",
       "      <td>June, 2005</td>\n",
       "      <td>dystopian</td>\n",
       "      <td>0.063022</td>\n",
       "      <td>0.058575</td>\n",
       "      <td>0.689195</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>1580</td>\n",
       "      <td>1577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Kilmeny of the Orchard</td>\n",
       "      <td>5341.txt</td>\n",
       "      <td>Kilmeny of the Orchard</td>\n",
       "      <td>Lucy Maud Montgomery</td>\n",
       "      <td>March, 2004</td>\n",
       "      <td>romance</td>\n",
       "      <td>0.077769</td>\n",
       "      <td>0.052053</td>\n",
       "      <td>0.673287</td>\n",
       "      <td>0.048488</td>\n",
       "      <td>1384</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Narcissus</td>\n",
       "      <td>42533-8.txt</td>\n",
       "      <td>Narcissus</td>\n",
       "      <td>Evelyn Scott</td>\n",
       "      <td>April 14, 2013</td>\n",
       "      <td>horror</td>\n",
       "      <td>0.075274</td>\n",
       "      <td>0.078131</td>\n",
       "      <td>0.663339</td>\n",
       "      <td>-0.002113</td>\n",
       "      <td>1716</td>\n",
       "      <td>1674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The Martian</td>\n",
       "      <td>40992.txt</td>\n",
       "      <td>The Martian</td>\n",
       "      <td>Allen Glasser</td>\n",
       "      <td>October 9, 2012</td>\n",
       "      <td>horror</td>\n",
       "      <td>0.052421</td>\n",
       "      <td>0.045618</td>\n",
       "      <td>0.648011</td>\n",
       "      <td>0.014135</td>\n",
       "      <td>293</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>Just David</td>\n",
       "      <td>440.txt</td>\n",
       "      <td>Just David</td>\n",
       "      <td>Eleanor H. Porter</td>\n",
       "      <td>February, 1996</td>\n",
       "      <td>children</td>\n",
       "      <td>0.058199</td>\n",
       "      <td>0.040172</td>\n",
       "      <td>0.648420</td>\n",
       "      <td>0.037581</td>\n",
       "      <td>1444</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Jewels of Gwahlur</td>\n",
       "      <td>42236-8.txt</td>\n",
       "      <td>Jewels of Gwahlur</td>\n",
       "      <td>Robert E. Howard</td>\n",
       "      <td>March 1, 2013</td>\n",
       "      <td>fantasi</td>\n",
       "      <td>0.052192</td>\n",
       "      <td>0.060173</td>\n",
       "      <td>0.716662</td>\n",
       "      <td>-0.009778</td>\n",
       "      <td>429</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Physics</td>\n",
       "      <td>40175-0.txt</td>\n",
       "      <td>Physics</td>\n",
       "      <td>Willis Eugene Tower</td>\n",
       "      <td>July 9, 2012</td>\n",
       "      <td>textbook</td>\n",
       "      <td>0.034654</td>\n",
       "      <td>0.017144</td>\n",
       "      <td>0.719065</td>\n",
       "      <td>0.024866</td>\n",
       "      <td>2047</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Eight Hundred Leagues on the Amazon</td>\n",
       "      <td>3091-8.txt</td>\n",
       "      <td>Eight Hundred Leagues on the Amazon</td>\n",
       "      <td>Jules Verne</td>\n",
       "      <td>February, 2002</td>\n",
       "      <td>adventur</td>\n",
       "      <td>0.059306</td>\n",
       "      <td>0.038590</td>\n",
       "      <td>0.669637</td>\n",
       "      <td>0.036644</td>\n",
       "      <td>2528</td>\n",
       "      <td>1654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>The Forest</td>\n",
       "      <td>9376-8.txt</td>\n",
       "      <td>The Forest</td>\n",
       "      <td>Stewart Edward White</td>\n",
       "      <td>November, 2005</td>\n",
       "      <td>histor</td>\n",
       "      <td>0.067549</td>\n",
       "      <td>0.044522</td>\n",
       "      <td>0.725843</td>\n",
       "      <td>0.043910</td>\n",
       "      <td>1439</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>Vera</td>\n",
       "      <td>1843.txt</td>\n",
       "      <td>Vera</td>\n",
       "      <td>Richard Harding Davis</td>\n",
       "      <td>August, 1999</td>\n",
       "      <td>dystopian</td>\n",
       "      <td>0.059879</td>\n",
       "      <td>0.057267</td>\n",
       "      <td>0.624295</td>\n",
       "      <td>0.014338</td>\n",
       "      <td>787</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>Further Adventures of Lad</td>\n",
       "      <td>2392.txt</td>\n",
       "      <td>Further Adventures of Lad</td>\n",
       "      <td>Albert Payson Terhune</td>\n",
       "      <td>November, 2000</td>\n",
       "      <td>young adult</td>\n",
       "      <td>0.061265</td>\n",
       "      <td>0.061412</td>\n",
       "      <td>0.686714</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>1876</td>\n",
       "      <td>1857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>The Woodlanders</td>\n",
       "      <td>482.txt</td>\n",
       "      <td>The Woodlanders</td>\n",
       "      <td>Thomas Hardy</td>\n",
       "      <td>April, 1996</td>\n",
       "      <td>novel</td>\n",
       "      <td>0.063831</td>\n",
       "      <td>0.046271</td>\n",
       "      <td>0.702874</td>\n",
       "      <td>0.034806</td>\n",
       "      <td>3324</td>\n",
       "      <td>2568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Revenge!</td>\n",
       "      <td>8668.txt</td>\n",
       "      <td>Revenge!</td>\n",
       "      <td>by Robert Barr</td>\n",
       "      <td>November 20, 2004</td>\n",
       "      <td>children</td>\n",
       "      <td>0.061342</td>\n",
       "      <td>0.057172</td>\n",
       "      <td>0.662751</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>2270</td>\n",
       "      <td>1908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>Anne of Geierstein</td>\n",
       "      <td>44247.txt</td>\n",
       "      <td>Anne of Geierstein</td>\n",
       "      <td>Walter Scott</td>\n",
       "      <td>November 21, 2013</td>\n",
       "      <td>histor</td>\n",
       "      <td>0.080691</td>\n",
       "      <td>0.054442</td>\n",
       "      <td>0.716062</td>\n",
       "      <td>0.048409</td>\n",
       "      <td>3268</td>\n",
       "      <td>2205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>The Red and the Black</td>\n",
       "      <td>44747-8.txt</td>\n",
       "      <td>The Red and the Black</td>\n",
       "      <td>Stendhal</td>\n",
       "      <td>January 24, 2014</td>\n",
       "      <td>bildungsroman</td>\n",
       "      <td>0.084110</td>\n",
       "      <td>0.061912</td>\n",
       "      <td>0.665531</td>\n",
       "      <td>0.044361</td>\n",
       "      <td>6671</td>\n",
       "      <td>4974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Prince Otto</td>\n",
       "      <td>372-0.txt</td>\n",
       "      <td>Prince Otto</td>\n",
       "      <td>Robert Louis Stevenson</td>\n",
       "      <td>September 3, 2010</td>\n",
       "      <td>novel</td>\n",
       "      <td>0.078291</td>\n",
       "      <td>0.056598</td>\n",
       "      <td>0.659329</td>\n",
       "      <td>0.045586</td>\n",
       "      <td>1892</td>\n",
       "      <td>1352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>Married</td>\n",
       "      <td>7956.txt</td>\n",
       "      <td>Married</td>\n",
       "      <td>August Strindberg</td>\n",
       "      <td>April, 2005</td>\n",
       "      <td>novel</td>\n",
       "      <td>0.066433</td>\n",
       "      <td>0.051939</td>\n",
       "      <td>0.645409</td>\n",
       "      <td>0.028989</td>\n",
       "      <td>2400</td>\n",
       "      <td>1824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Riders of the Purple Sage</td>\n",
       "      <td>1300.txt</td>\n",
       "      <td>Riders of the Purple Sage</td>\n",
       "      <td>Zane Grey</td>\n",
       "      <td>April, 2000</td>\n",
       "      <td>western</td>\n",
       "      <td>0.064829</td>\n",
       "      <td>0.057441</td>\n",
       "      <td>0.675623</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>2763</td>\n",
       "      <td>2473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>The Emerald City of Oz</td>\n",
       "      <td>41667.txt</td>\n",
       "      <td>The Emerald City of Oz</td>\n",
       "      <td>L. Frank Baum</td>\n",
       "      <td>December 20, 2012</td>\n",
       "      <td>children</td>\n",
       "      <td>0.066339</td>\n",
       "      <td>0.038862</td>\n",
       "      <td>0.610252</td>\n",
       "      <td>0.048139</td>\n",
       "      <td>1754</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Growing Up</td>\n",
       "      <td>42408.txt</td>\n",
       "      <td>Growing Up</td>\n",
       "      <td>Jennie M. Drinkwater</td>\n",
       "      <td>March 24, 2013</td>\n",
       "      <td>autobiographi</td>\n",
       "      <td>0.068698</td>\n",
       "      <td>0.032124</td>\n",
       "      <td>0.627357</td>\n",
       "      <td>0.065015</td>\n",
       "      <td>2488</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>1260.txt</td>\n",
       "      <td>Jane Eyre</td>\n",
       "      <td>Charlotte Bronte</td>\n",
       "      <td>April 29, 2007</td>\n",
       "      <td>novel</td>\n",
       "      <td>0.070047</td>\n",
       "      <td>0.051378</td>\n",
       "      <td>0.671672</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>5240</td>\n",
       "      <td>3684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>White Fang</td>\n",
       "      <td>910.txt</td>\n",
       "      <td>White Fang</td>\n",
       "      <td>Jack London</td>\n",
       "      <td>March 16, 2005</td>\n",
       "      <td>adventur</td>\n",
       "      <td>0.059367</td>\n",
       "      <td>0.073029</td>\n",
       "      <td>0.702723</td>\n",
       "      <td>-0.025900</td>\n",
       "      <td>1591</td>\n",
       "      <td>2072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Murat</td>\n",
       "      <td>2755.txt</td>\n",
       "      <td>Murat</td>\n",
       "      <td>Alexandre Dumas, Pere</td>\n",
       "      <td>August 15, 2006</td>\n",
       "      <td>histor</td>\n",
       "      <td>0.049689</td>\n",
       "      <td>0.043030</td>\n",
       "      <td>0.671667</td>\n",
       "      <td>0.012358</td>\n",
       "      <td>379</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>The Sorrows of Satan</td>\n",
       "      <td>42332-8.txt</td>\n",
       "      <td>The Sorrows of Satan</td>\n",
       "      <td>Marie Corelli</td>\n",
       "      <td>March 14, 2013</td>\n",
       "      <td>horror</td>\n",
       "      <td>0.102658</td>\n",
       "      <td>0.064964</td>\n",
       "      <td>0.676426</td>\n",
       "      <td>0.069003</td>\n",
       "      <td>6364</td>\n",
       "      <td>4090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>On the Eve</td>\n",
       "      <td>6902.txt</td>\n",
       "      <td>On the Eve</td>\n",
       "      <td>Ivan Turgenev</td>\n",
       "      <td>November, 2004</td>\n",
       "      <td>romance</td>\n",
       "      <td>0.067337</td>\n",
       "      <td>0.048816</td>\n",
       "      <td>0.666247</td>\n",
       "      <td>0.039377</td>\n",
       "      <td>1580</td>\n",
       "      <td>1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>Ruth Hall</td>\n",
       "      <td>40814.txt</td>\n",
       "      <td>Ruth Hall</td>\n",
       "      <td>Fanny Fern</td>\n",
       "      <td>September 22, 2012</td>\n",
       "      <td>roman clef</td>\n",
       "      <td>0.069253</td>\n",
       "      <td>0.043717</td>\n",
       "      <td>0.664773</td>\n",
       "      <td>0.049064</td>\n",
       "      <td>2168</td>\n",
       "      <td>1382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>The Second Jungle Book</td>\n",
       "      <td>1937.txt</td>\n",
       "      <td>The Second Jungle Book</td>\n",
       "      <td>Rudyard Kipling</td>\n",
       "      <td>October, 1999</td>\n",
       "      <td>children</td>\n",
       "      <td>0.047260</td>\n",
       "      <td>0.055604</td>\n",
       "      <td>0.719089</td>\n",
       "      <td>-0.012617</td>\n",
       "      <td>1129</td>\n",
       "      <td>1352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>Spiders</td>\n",
       "      <td>44496.txt</td>\n",
       "      <td>Spiders</td>\n",
       "      <td>Cecil Warburton</td>\n",
       "      <td>December 24, 2013</td>\n",
       "      <td>detect</td>\n",
       "      <td>0.050037</td>\n",
       "      <td>0.029775</td>\n",
       "      <td>0.732583</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>808</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>The Mediterranean</td>\n",
       "      <td>41263.txt</td>\n",
       "      <td>The Mediterranean</td>\n",
       "      <td>T. G. (Thomas Gray) Bonney, E. A. R. Ball, H. ...</td>\n",
       "      <td>November 2, 2012</td>\n",
       "      <td>adventur</td>\n",
       "      <td>0.077451</td>\n",
       "      <td>0.035116</td>\n",
       "      <td>0.768497</td>\n",
       "      <td>0.083011</td>\n",
       "      <td>3274</td>\n",
       "      <td>1608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>Dorothy</td>\n",
       "      <td>40300-8.txt</td>\n",
       "      <td>Dorothy</td>\n",
       "      <td>Evelyn Raymond</td>\n",
       "      <td>July 22, 2012</td>\n",
       "      <td>fantasi</td>\n",
       "      <td>0.074698</td>\n",
       "      <td>0.050853</td>\n",
       "      <td>0.678489</td>\n",
       "      <td>0.047668</td>\n",
       "      <td>1699</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>Blood Brothers</td>\n",
       "      <td>8423-8.txt</td>\n",
       "      <td>Blood Brothers</td>\n",
       "      <td>Colonel Eugene C. Jacobs</td>\n",
       "      <td>July, 2005</td>\n",
       "      <td>horror</td>\n",
       "      <td>0.043034</td>\n",
       "      <td>0.053077</td>\n",
       "      <td>0.630993</td>\n",
       "      <td>-0.018963</td>\n",
       "      <td>806</td>\n",
       "      <td>879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>The Wallet of Kai Lung</td>\n",
       "      <td>1076.txt</td>\n",
       "      <td>The Wallet of Kai Lung</td>\n",
       "      <td>Ernest Bramah</td>\n",
       "      <td>October, 1997</td>\n",
       "      <td>fantasi</td>\n",
       "      <td>0.094572</td>\n",
       "      <td>0.051314</td>\n",
       "      <td>0.752148</td>\n",
       "      <td>0.072379</td>\n",
       "      <td>3139</td>\n",
       "      <td>1654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>All Roads Lead to Calvary</td>\n",
       "      <td>2231.txt</td>\n",
       "      <td>All Roads Lead to Calvary</td>\n",
       "      <td>Jerome K. Jerome</td>\n",
       "      <td>March 24, 2005</td>\n",
       "      <td>drama</td>\n",
       "      <td>0.073767</td>\n",
       "      <td>0.053722</td>\n",
       "      <td>0.675367</td>\n",
       "      <td>0.037181</td>\n",
       "      <td>2592</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>Akbar</td>\n",
       "      <td>40155.txt</td>\n",
       "      <td>Akbar</td>\n",
       "      <td>P. A. S. van Limburg-Brouwer</td>\n",
       "      <td>July 7, 2012</td>\n",
       "      <td>syair</td>\n",
       "      <td>0.088927</td>\n",
       "      <td>0.047641</td>\n",
       "      <td>0.701412</td>\n",
       "      <td>0.078233</td>\n",
       "      <td>2988</td>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>915 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title     filename  \\\n",
       "0                                  Jonah     3678.txt   \n",
       "1             King--of the Khyber Rifles     6066.txt   \n",
       "2                The Wind in the Willows      289.txt   \n",
       "3                                  Akbar  40155-8.txt   \n",
       "4                                Erewhon     1906.txt   \n",
       "5                          Night and Day     1245.txt   \n",
       "6                          She and Allan     5745.txt   \n",
       "7                  The Amateur Cracksman      706.txt   \n",
       "8                     Anne of Geierstein  44247-8.txt   \n",
       "9                         A Tramp Abroad     5786.txt   \n",
       "10                 Captives of the Flame    41905.txt   \n",
       "11                      Madame de Mauves     7813.txt   \n",
       "12               Five Weeks in a Balloon     3526.txt   \n",
       "13                                  Tara    45430.txt   \n",
       "14              The Mysteries of Udolpho     3268.txt   \n",
       "15                   Notre-Dame de Paris     2610.txt   \n",
       "16                                Clocks      855.txt   \n",
       "17                            Green Eyes  45557-8.txt   \n",
       "18                            Botticelli  39942-8.txt   \n",
       "19                   The Longest Journey     2604.txt   \n",
       "20     Down and Out in the Magic Kingdom   8086-8.txt   \n",
       "21                              Meccania    44074.txt   \n",
       "22                              Leinster    43096.txt   \n",
       "23                        Off on a Comet   1353-8.txt   \n",
       "24                       The Ivory Trail     5194.txt   \n",
       "25                       Sketches by Boz      882.txt   \n",
       "26                                Hunger   8387-8.txt   \n",
       "27                Kilmeny of the Orchard     5341.txt   \n",
       "28                             Narcissus  42533-8.txt   \n",
       "29                           The Martian    40992.txt   \n",
       "..                                   ...          ...   \n",
       "885                           Just David      440.txt   \n",
       "886                    Jewels of Gwahlur  42236-8.txt   \n",
       "887                              Physics  40175-0.txt   \n",
       "888  Eight Hundred Leagues on the Amazon   3091-8.txt   \n",
       "889                           The Forest   9376-8.txt   \n",
       "890                                 Vera     1843.txt   \n",
       "891            Further Adventures of Lad     2392.txt   \n",
       "892                      The Woodlanders      482.txt   \n",
       "893                             Revenge!     8668.txt   \n",
       "894                   Anne of Geierstein    44247.txt   \n",
       "895                The Red and the Black  44747-8.txt   \n",
       "896                          Prince Otto    372-0.txt   \n",
       "897                              Married     7956.txt   \n",
       "898            Riders of the Purple Sage     1300.txt   \n",
       "899               The Emerald City of Oz    41667.txt   \n",
       "900                           Growing Up    42408.txt   \n",
       "901                            Jane Eyre     1260.txt   \n",
       "902                           White Fang      910.txt   \n",
       "903                                Murat     2755.txt   \n",
       "904                 The Sorrows of Satan  42332-8.txt   \n",
       "905                           On the Eve     6902.txt   \n",
       "906                            Ruth Hall    40814.txt   \n",
       "907               The Second Jungle Book     1937.txt   \n",
       "908                              Spiders    44496.txt   \n",
       "909                    The Mediterranean    41263.txt   \n",
       "910                              Dorothy  40300-8.txt   \n",
       "911                       Blood Brothers   8423-8.txt   \n",
       "912               The Wallet of Kai Lung     1076.txt   \n",
       "913            All Roads Lead to Calvary     2231.txt   \n",
       "914                                Akbar    40155.txt   \n",
       "\n",
       "                                 title.1  \\\n",
       "0                                  Jonah   \n",
       "1             King--of the Khyber Rifles   \n",
       "2                The Wind in the Willows   \n",
       "3                                  Akbar   \n",
       "4                                Erewhon   \n",
       "5                          Night and Day   \n",
       "6                          She and Allan   \n",
       "7                  The Amateur Cracksman   \n",
       "8                     Anne of Geierstein   \n",
       "9                         A Tramp Abroad   \n",
       "10                 Captives of the Flame   \n",
       "11                      Madame de Mauves   \n",
       "12               Five Weeks in a Balloon   \n",
       "13                                  Tara   \n",
       "14              The Mysteries of Udolpho   \n",
       "15                   Notre-Dame de Paris   \n",
       "16                                Clocks   \n",
       "17                            Green Eyes   \n",
       "18                            Botticelli   \n",
       "19                   The Longest Journey   \n",
       "20     Down and Out in the Magic Kingdom   \n",
       "21                              Meccania   \n",
       "22                              Leinster   \n",
       "23                        Off on a Comet   \n",
       "24                       The Ivory Trail   \n",
       "25                       Sketches by Boz   \n",
       "26                                Hunger   \n",
       "27                Kilmeny of the Orchard   \n",
       "28                             Narcissus   \n",
       "29                           The Martian   \n",
       "..                                   ...   \n",
       "885                           Just David   \n",
       "886                    Jewels of Gwahlur   \n",
       "887                              Physics   \n",
       "888  Eight Hundred Leagues on the Amazon   \n",
       "889                           The Forest   \n",
       "890                                 Vera   \n",
       "891            Further Adventures of Lad   \n",
       "892                      The Woodlanders   \n",
       "893                             Revenge!   \n",
       "894                   Anne of Geierstein   \n",
       "895                The Red and the Black   \n",
       "896                          Prince Otto   \n",
       "897                              Married   \n",
       "898            Riders of the Purple Sage   \n",
       "899               The Emerald City of Oz   \n",
       "900                           Growing Up   \n",
       "901                            Jane Eyre   \n",
       "902                           White Fang   \n",
       "903                                Murat   \n",
       "904                 The Sorrows of Satan   \n",
       "905                           On the Eve   \n",
       "906                            Ruth Hall   \n",
       "907               The Second Jungle Book   \n",
       "908                              Spiders   \n",
       "909                    The Mediterranean   \n",
       "910                              Dorothy   \n",
       "911                       Blood Brothers   \n",
       "912               The Wallet of Kai Lung   \n",
       "913            All Roads Lead to Calvary   \n",
       "914                                Akbar   \n",
       "\n",
       "                                                author         release year  \\\n",
       "0                                          Louis Stone        January, 2003   \n",
       "1                                         Talbot Mundy         July, 2004     \n",
       "2                                      Kenneth Grahame           July, 1995   \n",
       "3                         P. A. S. van Limburg-Brouwer        July 7, 2012    \n",
       "4                                        Samuel Butler     March 20, 2005     \n",
       "5                                       Virginia Woolf          March, 1998   \n",
       "6                                     H. Rider Haggard      April 22, 2006    \n",
       "7                                        E. W. Hornung       November, 1996   \n",
       "8                                         Walter Scott   November 21, 2013    \n",
       "9                          Mark Twain (Samuel Clemens)          March 1994    \n",
       "10                                    Samuel R. Delany    January 24, 2013    \n",
       "11                                         Henry James         April, 2005    \n",
       "12                                         Jules Verne      November, 2002    \n",
       "13                               Philip Meadows Taylor      April 18, 2014    \n",
       "14                                       Ann Radcliffe           June, 2002   \n",
       "15                                         Victor Hugo        April, 2001     \n",
       "16                                    Jerome K. Jerome          March, 1997   \n",
       "17                                        Roy J. Snell         May 1, 2014    \n",
       "18                                   Henry Bryan Binns        June 7, 2012    \n",
       "19                                       E. M. Forster          April, 2001   \n",
       "20                                       Cory Doctorow            May, 2005   \n",
       "21                                        Owen Gregory    October 30, 2013    \n",
       "22                                Stephen Lucius Gwynn        July 5, 2013    \n",
       "23                                         Jules Verne           June, 1998   \n",
       "24                                        Talbot Mundy       February, 2004   \n",
       "25                                     Charles Dickens   December 6, 2009     \n",
       "26                                         Knut Hamsun           June, 2005   \n",
       "27                                Lucy Maud Montgomery         March, 2004    \n",
       "28                                        Evelyn Scott      April 14, 2013    \n",
       "29                                       Allen Glasser     October 9, 2012    \n",
       "..                                                 ...                  ...   \n",
       "885                                  Eleanor H. Porter       February, 1996   \n",
       "886                                   Robert E. Howard       March 1, 2013    \n",
       "887                                Willis Eugene Tower        July 9, 2012    \n",
       "888                                        Jules Verne       February, 2002   \n",
       "889                               Stewart Edward White       November, 2005   \n",
       "890                              Richard Harding Davis         August, 1999   \n",
       "891                              Albert Payson Terhune       November, 2000   \n",
       "892                                       Thomas Hardy          April, 1996   \n",
       "893                                     by Robert Barr  November 20, 2004     \n",
       "894                                       Walter Scott   November 21, 2013    \n",
       "895                                           Stendhal    January 24, 2014    \n",
       "896                             Robert Louis Stevenson  September 3, 2010     \n",
       "897                                  August Strindberg         April, 2005    \n",
       "898                                          Zane Grey          April, 2000   \n",
       "899                                      L. Frank Baum   December 20, 2012    \n",
       "900                               Jennie M. Drinkwater      March 24, 2013    \n",
       "901                                   Charlotte Bronte     April 29, 2007     \n",
       "902                                        Jack London     March 16, 2005     \n",
       "903                              Alexandre Dumas, Pere     August 15, 2006    \n",
       "904                                      Marie Corelli      March 14, 2013    \n",
       "905                                      Ivan Turgenev      November, 2004    \n",
       "906                                         Fanny Fern  September 22, 2012    \n",
       "907                                    Rudyard Kipling        October, 1999   \n",
       "908                                    Cecil Warburton   December 24, 2013    \n",
       "909  T. G. (Thomas Gray) Bonney, E. A. R. Ball, H. ...   November 2, 2012     \n",
       "910                                     Evelyn Raymond       July 22, 2012    \n",
       "911                           Colonel Eugene C. Jacobs           July, 2005   \n",
       "912                                      Ernest Bramah        October, 1997   \n",
       "913                                   Jerome K. Jerome     March 24, 2005     \n",
       "914                       P. A. S. van Limburg-Brouwer        July 7, 2012    \n",
       "\n",
       "                   genre  pos score  neg score  neu score  comp score  \\\n",
       "0                 poetri   0.063752   0.064028   0.670289    0.001590   \n",
       "1               adventur   0.056072   0.044295   0.660100    0.020974   \n",
       "2               children   0.075622   0.049711   0.708466    0.050425   \n",
       "3                  syair   0.088927   0.047641   0.701412    0.078233   \n",
       "4                  satir   0.075006   0.061587   0.750951    0.025886   \n",
       "5                romance   0.070135   0.048907   0.711205    0.043948   \n",
       "6                fantasi   0.067608   0.057010   0.693447    0.020357   \n",
       "7                  crime   0.059576   0.045972   0.663071    0.026517   \n",
       "8                 histor   0.080691   0.054442   0.716062    0.048409   \n",
       "9                 travel   0.062378   0.037464   0.720202    0.047015   \n",
       "10       science fiction   0.037854   0.037340   0.663475    0.001440   \n",
       "11               novella   0.098595   0.055954   0.732808    0.084604   \n",
       "12              adventur   0.051753   0.041392   0.660914    0.018097   \n",
       "13          prose poetri   0.072001   0.055000   0.696242    0.031076   \n",
       "14                gothic   0.073049   0.068802   0.734536    0.009785   \n",
       "15              dystopia   0.057745   0.052302   0.675644    0.011826   \n",
       "16                 drama   0.070207   0.041800   0.673357    0.055263   \n",
       "17           young adult   0.052123   0.043438   0.606841    0.023032   \n",
       "18               mysteri   0.065328   0.026211   0.714379    0.072371   \n",
       "19         bildungsroman   0.066929   0.056150   0.652915    0.021845   \n",
       "20       science fiction   0.059361   0.044526   0.652722    0.026161   \n",
       "21   utopiananddystopian   0.069571   0.034635   0.739040    0.062762   \n",
       "22       science fiction   0.076081   0.033165   0.747439    0.080475   \n",
       "23       science fiction   0.058780   0.040971   0.698877    0.032333   \n",
       "24                horror   0.055556   0.054841   0.683443   -0.000180   \n",
       "25          sketch stori   0.078445   0.048444   0.724015    0.057092   \n",
       "26             dystopian   0.063022   0.058575   0.689195    0.010762   \n",
       "27               romance   0.077769   0.052053   0.673287    0.048488   \n",
       "28                horror   0.075274   0.078131   0.663339   -0.002113   \n",
       "29                horror   0.052421   0.045618   0.648011    0.014135   \n",
       "..                   ...        ...        ...        ...         ...   \n",
       "885             children   0.058199   0.040172   0.648420    0.037581   \n",
       "886              fantasi   0.052192   0.060173   0.716662   -0.009778   \n",
       "887             textbook   0.034654   0.017144   0.719065    0.024866   \n",
       "888             adventur   0.059306   0.038590   0.669637    0.036644   \n",
       "889               histor   0.067549   0.044522   0.725843    0.043910   \n",
       "890            dystopian   0.059879   0.057267   0.624295    0.014338   \n",
       "891          young adult   0.061265   0.061412   0.686714    0.003181   \n",
       "892                novel   0.063831   0.046271   0.702874    0.034806   \n",
       "893             children   0.061342   0.057172   0.662751    0.007823   \n",
       "894               histor   0.080691   0.054442   0.716062    0.048409   \n",
       "895        bildungsroman   0.084110   0.061912   0.665531    0.044361   \n",
       "896                novel   0.078291   0.056598   0.659329    0.045586   \n",
       "897                novel   0.066433   0.051939   0.645409    0.028989   \n",
       "898              western   0.064829   0.057441   0.675623    0.016212   \n",
       "899             children   0.066339   0.038862   0.610252    0.048139   \n",
       "900        autobiographi   0.068698   0.032124   0.627357    0.065015   \n",
       "901                novel   0.070047   0.051378   0.671672    0.035903   \n",
       "902             adventur   0.059367   0.073029   0.702723   -0.025900   \n",
       "903               histor   0.049689   0.043030   0.671667    0.012358   \n",
       "904               horror   0.102658   0.064964   0.676426    0.069003   \n",
       "905              romance   0.067337   0.048816   0.666247    0.039377   \n",
       "906           roman clef   0.069253   0.043717   0.664773    0.049064   \n",
       "907             children   0.047260   0.055604   0.719089   -0.012617   \n",
       "908               detect   0.050037   0.029775   0.732583    0.036072   \n",
       "909             adventur   0.077451   0.035116   0.768497    0.083011   \n",
       "910              fantasi   0.074698   0.050853   0.678489    0.047668   \n",
       "911               horror   0.043034   0.053077   0.630993   -0.018963   \n",
       "912              fantasi   0.094572   0.051314   0.752148    0.072379   \n",
       "913                drama   0.073767   0.053722   0.675367    0.037181   \n",
       "914                syair   0.088927   0.047641   0.701412    0.078233   \n",
       "\n",
       "     amt pos  amt neg  \n",
       "0       2058     2017  \n",
       "1       2518     2115  \n",
       "2       1684     1172  \n",
       "3       2988     1652  \n",
       "4       2506     1952  \n",
       "5       4822     3088  \n",
       "6       3234     2652  \n",
       "7       1363     1072  \n",
       "8       3268     2205  \n",
       "9        642      387  \n",
       "10       850      776  \n",
       "11      1301      744  \n",
       "12      2156     1643  \n",
       "13      6587     5509  \n",
       "14      7454     7002  \n",
       "15      4271     3857  \n",
       "16       218      125  \n",
       "17       972      760  \n",
       "18       317      120  \n",
       "19      2607     1997  \n",
       "20      1322      893  \n",
       "21      2146      990  \n",
       "22       509      237  \n",
       "23      2575     1785  \n",
       "24      3347     3419  \n",
       "25      7439     4611  \n",
       "26      1580     1577  \n",
       "27      1384      925  \n",
       "28      1716     1674  \n",
       "29       293      251  \n",
       "..       ...      ...  \n",
       "885     1444      987  \n",
       "886      429      490  \n",
       "887     2047     1113  \n",
       "888     2528     1654  \n",
       "889     1439      893  \n",
       "890      787      679  \n",
       "891     1876     1857  \n",
       "892     3324     2568  \n",
       "893     2270     1908  \n",
       "894     3268     2205  \n",
       "895     6671     4974  \n",
       "896     1892     1352  \n",
       "897     2400     1824  \n",
       "898     2763     2473  \n",
       "899     1754     1068  \n",
       "900     2488     1099  \n",
       "901     5240     3684  \n",
       "902     1591     2072  \n",
       "903      379      312  \n",
       "904     6364     4090  \n",
       "905     1580     1211  \n",
       "906     2168     1382  \n",
       "907     1129     1352  \n",
       "908      808      470  \n",
       "909     3274     1608  \n",
       "910     1699     1169  \n",
       "911      806      879  \n",
       "912     3139     1654  \n",
       "913     2592     1867  \n",
       "914     2988     1652  \n",
       "\n",
       "[915 rows x 12 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['christian',\n",
       " 'adventur',\n",
       " 'western',\n",
       " 'travel',\n",
       " 'comic',\n",
       " 'knstlerroman',\n",
       " 'adventur',\n",
       " 'children',\n",
       " 'satir',\n",
       " 'polit',\n",
       " 'children',\n",
       " 'children',\n",
       " 'young adult',\n",
       " 'science fiction',\n",
       " 'satir',\n",
       " 'detect',\n",
       " 'dystopian',\n",
       " 'horror',\n",
       " 'children',\n",
       " 'adventur',\n",
       " 'unknown',\n",
       " 'frame stori',\n",
       " 'histor',\n",
       " 'science',\n",
       " 'cryptozoolog',\n",
       " 'romance',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'adventur',\n",
       " 'nonsens poetri',\n",
       " 'nonfict',\n",
       " 'adventur',\n",
       " 'adventur',\n",
       " 'science fiction',\n",
       " 'science fiction',\n",
       " 'short stori',\n",
       " 'lost world genr',\n",
       " 'lost world genr',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'science fiction',\n",
       " 'literari realism',\n",
       " 'literari realism',\n",
       " 'children',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'histor',\n",
       " 'thriller',\n",
       " 'children',\n",
       " 'nonfict',\n",
       " 'fantasi',\n",
       " 'bildungsroman',\n",
       " 'nonprofit',\n",
       " 'biographi',\n",
       " 'autobiographi',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'literari realism',\n",
       " 'juvenil',\n",
       " 'novel of manner',\n",
       " 'black comedi',\n",
       " 'mysteri',\n",
       " 'science fiction',\n",
       " 'unknown',\n",
       " 'histor',\n",
       " 'romance',\n",
       " 'science fiction',\n",
       " 'mysteri',\n",
       " 'mysteri',\n",
       " 'novel',\n",
       " 'science fiction',\n",
       " 'science fiction',\n",
       " 'adventur',\n",
       " 'tragicomedi',\n",
       " 'mysteri',\n",
       " 'unknown',\n",
       " 'young adult',\n",
       " 'mysteri',\n",
       " 'thriller',\n",
       " 'detect stori',\n",
       " 'literari',\n",
       " 'histor',\n",
       " 'philosophi',\n",
       " 'gothic',\n",
       " 'selfhelp',\n",
       " 'apocalyptandpostapocalypt',\n",
       " 'satir',\n",
       " 'spi',\n",
       " 'unknown',\n",
       " 'novel',\n",
       " 'mysteri',\n",
       " 'children',\n",
       " 'travel',\n",
       " 'satir',\n",
       " 'war',\n",
       " 'war',\n",
       " 'mysteri',\n",
       " 'christian',\n",
       " 'dystopian',\n",
       " 'unknown',\n",
       " 'gothic',\n",
       " 'diariand',\n",
       " 'diariand',\n",
       " 'war',\n",
       " 'romantic',\n",
       " 'adventur',\n",
       " 'gothic',\n",
       " 'mysteri',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'novella',\n",
       " 'utopiananddystopian',\n",
       " 'bush poetri',\n",
       " 'adventur',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'horror',\n",
       " 'autobiograph',\n",
       " 'novella',\n",
       " 'detect',\n",
       " 'biograph',\n",
       " 'biographi',\n",
       " 'biographi',\n",
       " 'mysteri',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'epistolari',\n",
       " 'fantasi',\n",
       " 'children',\n",
       " 'adventur',\n",
       " 'literari realism',\n",
       " 'biographi',\n",
       " 'christian',\n",
       " 'fiction',\n",
       " 'fiction',\n",
       " 'hindi',\n",
       " 'romance',\n",
       " 'literari realism',\n",
       " 'histor',\n",
       " 'altern histori',\n",
       " 'epistolari',\n",
       " 'fantasi',\n",
       " 'unknown',\n",
       " 'bildungsroman',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'dystopia',\n",
       " 'dystopia',\n",
       " 'histor',\n",
       " 'satir',\n",
       " 'romantic',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'unknown',\n",
       " 'black comedi',\n",
       " 'black comedi',\n",
       " 'frame stori',\n",
       " 'frame stori',\n",
       " 'juvenil',\n",
       " 'children',\n",
       " 'children',\n",
       " 'children',\n",
       " 'novel',\n",
       " 'utopian',\n",
       " 'novella',\n",
       " 'detect',\n",
       " 'histor',\n",
       " 'adventur',\n",
       " 'children',\n",
       " 'fantasi',\n",
       " 'children',\n",
       " 'folklor',\n",
       " 'fantasi',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'fantasi',\n",
       " 'detect',\n",
       " 'adventur',\n",
       " 'philosophi',\n",
       " 'children',\n",
       " 'histor',\n",
       " 'unknown',\n",
       " 'fantasi',\n",
       " 'gothic',\n",
       " 'adventur',\n",
       " 'adventur',\n",
       " 'short stori',\n",
       " 'children',\n",
       " 'fantasi',\n",
       " 'gothic',\n",
       " 'unknown',\n",
       " 'adventur',\n",
       " 'nonfict',\n",
       " 'children',\n",
       " 'histor',\n",
       " 'unknown',\n",
       " 'science fiction',\n",
       " 'sensat',\n",
       " 'sensat',\n",
       " 'ruritanian romanc',\n",
       " 'natur write',\n",
       " 'poetri',\n",
       " 'histor',\n",
       " 'novel',\n",
       " 'young adult',\n",
       " 'histor',\n",
       " 'detect',\n",
       " 'horror',\n",
       " 'histor',\n",
       " 'canadian',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'science fiction',\n",
       " 'science fiction',\n",
       " 'comic',\n",
       " 'adventur',\n",
       " 'children',\n",
       " 'children',\n",
       " 'horror',\n",
       " 'children',\n",
       " 'science fiction',\n",
       " 'thriller',\n",
       " 'thriller',\n",
       " 'mysteri',\n",
       " 'mysteri',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'nonfict',\n",
       " 'science fiction',\n",
       " 'syair',\n",
       " 'crime',\n",
       " 'textbook',\n",
       " 'textbook',\n",
       " 'thriller',\n",
       " 'histor',\n",
       " 'fantasi',\n",
       " 'polit',\n",
       " 'interior design',\n",
       " 'histor',\n",
       " 'young adult',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'temper movement',\n",
       " 'temper movement',\n",
       " 'horror',\n",
       " 'philosophi',\n",
       " 'essay',\n",
       " 'short stori',\n",
       " 'short stori',\n",
       " 'roman clef',\n",
       " 'young adult',\n",
       " 'young adult',\n",
       " 'young adult',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'horror',\n",
       " 'children',\n",
       " 'children',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'travel',\n",
       " 'travel',\n",
       " 'fantasi',\n",
       " 'cookbook',\n",
       " 'cookbook',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'biographi',\n",
       " 'biographi',\n",
       " 'science fiction',\n",
       " 'science fiction',\n",
       " 'unknown',\n",
       " 'science fiction',\n",
       " 'adventur',\n",
       " 'pictur book',\n",
       " 'pictur book',\n",
       " 'young adult',\n",
       " 'thriller',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'novella',\n",
       " 'histori of idea',\n",
       " 'refer work',\n",
       " 'refer work',\n",
       " 'fantasi',\n",
       " 'polit',\n",
       " 'polit',\n",
       " 'christian',\n",
       " 'christian',\n",
       " 'children',\n",
       " 'science fiction',\n",
       " 'nonfict',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'science fiction',\n",
       " 'science fiction',\n",
       " 'gothic',\n",
       " 'autobiograph',\n",
       " 'autobiograph',\n",
       " 'autobiograph',\n",
       " 'adventur',\n",
       " 'adventur',\n",
       " 'histor',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'fiction',\n",
       " 'fantasi',\n",
       " 'sword and sorceri',\n",
       " 'sword and sorceri',\n",
       " 'children',\n",
       " 'children',\n",
       " 'sword and sorceri',\n",
       " 'sword and sorceri',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'detect',\n",
       " 'comedi',\n",
       " 'comedi',\n",
       " 'horror',\n",
       " 'gothic',\n",
       " 'autobiographi',\n",
       " 'biographi',\n",
       " 'detect',\n",
       " 'detect',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'children',\n",
       " 'children',\n",
       " 'children',\n",
       " 'crime',\n",
       " 'detect',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'science fiction',\n",
       " 'fantasi',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'nonfict',\n",
       " 'nonfict',\n",
       " 'encyclopedia',\n",
       " 'novella',\n",
       " 'novel',\n",
       " 'science fiction',\n",
       " 'western',\n",
       " 'western',\n",
       " 'detect',\n",
       " 'biograph',\n",
       " 'novel',\n",
       " 'children',\n",
       " 'nonfict',\n",
       " 'young adult',\n",
       " 'young adult',\n",
       " 'bildungsroman',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'children',\n",
       " 'fantasi',\n",
       " 'children',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'polit',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'science fiction']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the labels\n",
    "\n",
    "Encode the labels to one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test = data.labels_to_vectors(dataset.label_dataset,y_train, y_test)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert tokenlist to vectors\n",
    "\n",
    "### Using sentiment-wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dataset.sentiment_dataset\n",
    "a = 'a s d fp sks dk fsji sdf'.split(' ')\n",
    "data.tokenlist_to_vector(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using polarization scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05957593, 0.04597156, 0.66307096, 0.02651661])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.polarization_scores_to_vector(dataset,'706.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NER scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "Although most of the input consists of classes, many classes will be correlated (e.g. related genres).\n",
    "Therefore a neural network is chosen to model the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 5096)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2 = models.to_vector(x_train, dataset)\n",
    "x_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 (5096,)\n",
      "output length 113\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(x_train2) # = length of the list of images (matrices)\n",
    "input_shape = x_train2.shape[1:] # = shape of an individual image (matrix)\n",
    "output_length = (y_train[0]).shape[0] # = length of an individual label\n",
    "print(n_samples, input_shape)\n",
    "print('output length', output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 256)               1304832   \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 113)               29041     \n",
      "=================================================================\n",
      "Total params: 1,333,873\n",
      "Trainable params: 1,333,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import models # src/models.py\n",
    "dropout = 0.20\n",
    "# model, summary = models.sequential(input_shape, output_length, dropout)\n",
    "def sequential(input_shape, output_length, dropout=0.10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu', input_shape=input_shape))\n",
    "    #model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(output_length, activation='softmax'))\n",
    "    # in addition, return a function that displays information about the model\n",
    "    return model, model.summary\n",
    "\n",
    "model, summary = sequential(input_shape, output_length, dropout)\n",
    "\n",
    "summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "- Categorical cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a batch size\n",
    "batch_size = round(16)\n",
    "# n epochs = n iterations over all the training data\n",
    "epochs = 220"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "### Show logs [here](http://localhost:6006/#scalars)\n",
    "\n",
    "When training a new model, close any _Tenserboard_ tab,\n",
    "\n",
    "then run ` make logs ` and start training.\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 100 samples\n",
      "Epoch 1/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.8772 - acc: 0.8840 - val_loss: 4.3365 - val_acc: 0.2900\n",
      "Epoch 2/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.8745 - acc: 0.8760 - val_loss: 4.3307 - val_acc: 0.2900\n",
      "Epoch 3/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.8710 - acc: 0.8740 - val_loss: 4.3323 - val_acc: 0.2900\n",
      "Epoch 4/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.8593 - acc: 0.8920 - val_loss: 4.3356 - val_acc: 0.2900\n",
      "Epoch 5/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.8592 - acc: 0.8840 - val_loss: 4.3409 - val_acc: 0.2900\n",
      "Epoch 6/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.8198 - acc: 0.8980 - val_loss: 4.3356 - val_acc: 0.3000\n",
      "Epoch 7/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.8284 - acc: 0.8980 - val_loss: 4.3320 - val_acc: 0.3000\n",
      "Epoch 8/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.8400 - acc: 0.8940 - val_loss: 4.3383 - val_acc: 0.2900\n",
      "Epoch 9/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.8129 - acc: 0.8940 - val_loss: 4.3382 - val_acc: 0.2900\n",
      "Epoch 10/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.8117 - acc: 0.8960 - val_loss: 4.3369 - val_acc: 0.2900\n",
      "Epoch 11/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.7937 - acc: 0.9120 - val_loss: 4.3400 - val_acc: 0.2900\n",
      "Epoch 12/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.7889 - acc: 0.9060 - val_loss: 4.3427 - val_acc: 0.2800\n",
      "Epoch 13/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.7897 - acc: 0.9000 - val_loss: 4.3411 - val_acc: 0.2900\n",
      "Epoch 14/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.7738 - acc: 0.9020 - val_loss: 4.3463 - val_acc: 0.2800\n",
      "Epoch 15/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.7629 - acc: 0.9000 - val_loss: 4.3445 - val_acc: 0.2900\n",
      "Epoch 16/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.7706 - acc: 0.8900 - val_loss: 4.3436 - val_acc: 0.2800\n",
      "Epoch 17/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.7526 - acc: 0.9060 - val_loss: 4.3418 - val_acc: 0.2900\n",
      "Epoch 18/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.7441 - acc: 0.9080 - val_loss: 4.3466 - val_acc: 0.2600\n",
      "Epoch 19/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.7320 - acc: 0.9000 - val_loss: 4.3467 - val_acc: 0.2800\n",
      "Epoch 20/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.7275 - acc: 0.9040 - val_loss: 4.3479 - val_acc: 0.2800\n",
      "Epoch 21/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.7249 - acc: 0.9160 - val_loss: 4.3501 - val_acc: 0.2900\n",
      "Epoch 22/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.7106 - acc: 0.9180 - val_loss: 4.3569 - val_acc: 0.2800\n",
      "Epoch 23/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.7178 - acc: 0.9020 - val_loss: 4.3500 - val_acc: 0.2800\n",
      "Epoch 24/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6939 - acc: 0.9180 - val_loss: 4.3556 - val_acc: 0.2800\n",
      "Epoch 25/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.7013 - acc: 0.9160 - val_loss: 4.3526 - val_acc: 0.2800\n",
      "Epoch 26/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6839 - acc: 0.9140 - val_loss: 4.3524 - val_acc: 0.2900\n",
      "Epoch 27/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6868 - acc: 0.9140 - val_loss: 4.3524 - val_acc: 0.2900\n",
      "Epoch 28/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6811 - acc: 0.9240 - val_loss: 4.3604 - val_acc: 0.2800\n",
      "Epoch 29/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6635 - acc: 0.9140 - val_loss: 4.3556 - val_acc: 0.2800\n",
      "Epoch 30/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6549 - acc: 0.9260 - val_loss: 4.3600 - val_acc: 0.2800\n",
      "Epoch 31/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6591 - acc: 0.9160 - val_loss: 4.3580 - val_acc: 0.2800\n",
      "Epoch 32/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.6537 - acc: 0.9320 - val_loss: 4.3603 - val_acc: 0.2800\n",
      "Epoch 33/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6438 - acc: 0.9180 - val_loss: 4.3553 - val_acc: 0.2900\n",
      "Epoch 34/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6320 - acc: 0.9280 - val_loss: 4.3577 - val_acc: 0.2900\n",
      "Epoch 35/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6311 - acc: 0.9160 - val_loss: 4.3662 - val_acc: 0.2800\n",
      "Epoch 36/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6154 - acc: 0.9340 - val_loss: 4.3710 - val_acc: 0.2900\n",
      "Epoch 37/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6166 - acc: 0.9340 - val_loss: 4.3695 - val_acc: 0.2900\n",
      "Epoch 38/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6134 - acc: 0.9320 - val_loss: 4.3640 - val_acc: 0.2900\n",
      "Epoch 39/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6038 - acc: 0.9320 - val_loss: 4.3657 - val_acc: 0.2900\n",
      "Epoch 40/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6010 - acc: 0.9340 - val_loss: 4.3661 - val_acc: 0.2900\n",
      "Epoch 41/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.6022 - acc: 0.9360 - val_loss: 4.3673 - val_acc: 0.2900\n",
      "Epoch 42/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5869 - acc: 0.9320 - val_loss: 4.3740 - val_acc: 0.2900\n",
      "Epoch 43/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5900 - acc: 0.9340 - val_loss: 4.3712 - val_acc: 0.2900\n",
      "Epoch 44/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5831 - acc: 0.9340 - val_loss: 4.3723 - val_acc: 0.2700\n",
      "Epoch 45/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5618 - acc: 0.9380 - val_loss: 4.3740 - val_acc: 0.2800\n",
      "Epoch 46/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5625 - acc: 0.9340 - val_loss: 4.3733 - val_acc: 0.2800\n",
      "Epoch 47/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5529 - acc: 0.9480 - val_loss: 4.3771 - val_acc: 0.2800\n",
      "Epoch 48/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5551 - acc: 0.9460 - val_loss: 4.3784 - val_acc: 0.2800\n",
      "Epoch 49/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5408 - acc: 0.9360 - val_loss: 4.3800 - val_acc: 0.2900\n",
      "Epoch 50/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5499 - acc: 0.9440 - val_loss: 4.3817 - val_acc: 0.2800\n",
      "Epoch 51/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5320 - acc: 0.9380 - val_loss: 4.3799 - val_acc: 0.2800\n",
      "Epoch 52/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5225 - acc: 0.9480 - val_loss: 4.3832 - val_acc: 0.2800\n",
      "Epoch 53/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5290 - acc: 0.9460 - val_loss: 4.3854 - val_acc: 0.2800\n",
      "Epoch 54/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5151 - acc: 0.9520 - val_loss: 4.3803 - val_acc: 0.2700\n",
      "Epoch 55/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.5102 - acc: 0.9500 - val_loss: 4.3846 - val_acc: 0.2700\n",
      "Epoch 56/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4921 - acc: 0.9520 - val_loss: 4.3833 - val_acc: 0.2800\n",
      "Epoch 57/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.5007 - acc: 0.9520 - val_loss: 4.3887 - val_acc: 0.2800\n",
      "Epoch 58/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4981 - acc: 0.9440 - val_loss: 4.3868 - val_acc: 0.2800\n",
      "Epoch 59/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4998 - acc: 0.9540 - val_loss: 4.3896 - val_acc: 0.2800\n",
      "Epoch 60/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4729 - acc: 0.9480 - val_loss: 4.3939 - val_acc: 0.2800\n",
      "Epoch 61/200\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.4831 - acc: 0.9520 - val_loss: 4.3984 - val_acc: 0.2800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4723 - acc: 0.9560 - val_loss: 4.4017 - val_acc: 0.2800\n",
      "Epoch 63/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4666 - acc: 0.9540 - val_loss: 4.3987 - val_acc: 0.2800\n",
      "Epoch 64/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4611 - acc: 0.9500 - val_loss: 4.3998 - val_acc: 0.2700\n",
      "Epoch 65/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4551 - acc: 0.9580 - val_loss: 4.4010 - val_acc: 0.2700\n",
      "Epoch 66/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4528 - acc: 0.9500 - val_loss: 4.3974 - val_acc: 0.2700\n",
      "Epoch 67/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4447 - acc: 0.9500 - val_loss: 4.3953 - val_acc: 0.2800\n",
      "Epoch 68/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4434 - acc: 0.9560 - val_loss: 4.4028 - val_acc: 0.2800\n",
      "Epoch 69/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4312 - acc: 0.9580 - val_loss: 4.4014 - val_acc: 0.2900\n",
      "Epoch 70/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4180 - acc: 0.9600 - val_loss: 4.4032 - val_acc: 0.2900\n",
      "Epoch 71/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4269 - acc: 0.9560 - val_loss: 4.4005 - val_acc: 0.2800\n",
      "Epoch 72/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4227 - acc: 0.9600 - val_loss: 4.4048 - val_acc: 0.2800\n",
      "Epoch 73/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4111 - acc: 0.9600 - val_loss: 4.4019 - val_acc: 0.2700\n",
      "Epoch 74/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4126 - acc: 0.9560 - val_loss: 4.3991 - val_acc: 0.2700\n",
      "Epoch 75/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4147 - acc: 0.9560 - val_loss: 4.4019 - val_acc: 0.2900\n",
      "Epoch 76/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.4086 - acc: 0.9620 - val_loss: 4.4063 - val_acc: 0.2700\n",
      "Epoch 77/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.4008 - acc: 0.9600 - val_loss: 4.4113 - val_acc: 0.2700\n",
      "Epoch 78/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3970 - acc: 0.9620 - val_loss: 4.4044 - val_acc: 0.2800\n",
      "Epoch 79/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3848 - acc: 0.9600 - val_loss: 4.4099 - val_acc: 0.2700\n",
      "Epoch 80/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.3830 - acc: 0.9560 - val_loss: 4.4082 - val_acc: 0.2800\n",
      "Epoch 81/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.3841 - acc: 0.9620 - val_loss: 4.4100 - val_acc: 0.2700\n",
      "Epoch 82/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.3786 - acc: 0.9600 - val_loss: 4.4066 - val_acc: 0.2800\n",
      "Epoch 83/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.3711 - acc: 0.9580 - val_loss: 4.4067 - val_acc: 0.2800\n",
      "Epoch 84/200\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.3680 - acc: 0.9580 - val_loss: 4.4134 - val_acc: 0.2800\n",
      "Epoch 85/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3569 - acc: 0.9640 - val_loss: 4.4196 - val_acc: 0.2700\n",
      "Epoch 86/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3670 - acc: 0.9600 - val_loss: 4.4188 - val_acc: 0.2700\n",
      "Epoch 87/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3617 - acc: 0.9600 - val_loss: 4.4160 - val_acc: 0.2700\n",
      "Epoch 88/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3557 - acc: 0.9680 - val_loss: 4.4201 - val_acc: 0.2700\n",
      "Epoch 89/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.3416 - acc: 0.9660 - val_loss: 4.4187 - val_acc: 0.2700\n",
      "Epoch 90/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3450 - acc: 0.9660 - val_loss: 4.4183 - val_acc: 0.2800\n",
      "Epoch 91/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.3449 - acc: 0.9620 - val_loss: 4.4137 - val_acc: 0.2800\n",
      "Epoch 92/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.3387 - acc: 0.9660 - val_loss: 4.4180 - val_acc: 0.2800\n",
      "Epoch 93/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.3391 - acc: 0.9640 - val_loss: 4.4176 - val_acc: 0.2800\n",
      "Epoch 94/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.3158 - acc: 0.9660 - val_loss: 4.4238 - val_acc: 0.2800\n",
      "Epoch 95/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.3244 - acc: 0.9680 - val_loss: 4.4227 - val_acc: 0.2800\n",
      "Epoch 96/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.3277 - acc: 0.9680 - val_loss: 4.4220 - val_acc: 0.2800\n",
      "Epoch 97/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.3193 - acc: 0.9640 - val_loss: 4.4204 - val_acc: 0.2800\n",
      "Epoch 98/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.3220 - acc: 0.9640 - val_loss: 4.4214 - val_acc: 0.2800\n",
      "Epoch 99/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.3160 - acc: 0.9640 - val_loss: 4.4220 - val_acc: 0.2800\n",
      "Epoch 100/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.3101 - acc: 0.9680 - val_loss: 4.4248 - val_acc: 0.2800\n",
      "Epoch 101/200\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.3083 - acc: 0.9680 - val_loss: 4.4273 - val_acc: 0.2800\n",
      "Epoch 102/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2984 - acc: 0.9660 - val_loss: 4.4318 - val_acc: 0.2800\n",
      "Epoch 103/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.3018 - acc: 0.9700 - val_loss: 4.4375 - val_acc: 0.2800\n",
      "Epoch 104/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2876 - acc: 0.9720 - val_loss: 4.4295 - val_acc: 0.2800\n",
      "Epoch 105/200\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.2987 - acc: 0.9700 - val_loss: 4.4324 - val_acc: 0.2800\n",
      "Epoch 106/200\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.2945 - acc: 0.9720 - val_loss: 4.4263 - val_acc: 0.2900\n",
      "Epoch 107/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2869 - acc: 0.9680 - val_loss: 4.4340 - val_acc: 0.2800\n",
      "Epoch 108/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2869 - acc: 0.9700 - val_loss: 4.4326 - val_acc: 0.2900\n",
      "Epoch 109/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2791 - acc: 0.9740 - val_loss: 4.4307 - val_acc: 0.2800\n",
      "Epoch 110/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2761 - acc: 0.9720 - val_loss: 4.4350 - val_acc: 0.2800\n",
      "Epoch 111/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2734 - acc: 0.9780 - val_loss: 4.4366 - val_acc: 0.2800\n",
      "Epoch 112/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2772 - acc: 0.9640 - val_loss: 4.4393 - val_acc: 0.2800\n",
      "Epoch 113/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2726 - acc: 0.9740 - val_loss: 4.4399 - val_acc: 0.2800\n",
      "Epoch 114/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2550 - acc: 0.9720 - val_loss: 4.4394 - val_acc: 0.2800\n",
      "Epoch 115/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2582 - acc: 0.9760 - val_loss: 4.4374 - val_acc: 0.2800\n",
      "Epoch 116/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2563 - acc: 0.9780 - val_loss: 4.4387 - val_acc: 0.2700\n",
      "Epoch 117/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2546 - acc: 0.9760 - val_loss: 4.4394 - val_acc: 0.2800\n",
      "Epoch 118/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2509 - acc: 0.9780 - val_loss: 4.4425 - val_acc: 0.2700\n",
      "Epoch 119/200\n",
      "500/500 [==============================] - 2s 3ms/step - loss: 0.2514 - acc: 0.9740 - val_loss: 4.4430 - val_acc: 0.2800\n",
      "Epoch 120/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2466 - acc: 0.9780 - val_loss: 4.4467 - val_acc: 0.2800\n",
      "Epoch 121/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2383 - acc: 0.9740 - val_loss: 4.4492 - val_acc: 0.2800\n",
      "Epoch 122/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2407 - acc: 0.9760 - val_loss: 4.4498 - val_acc: 0.2800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2450 - acc: 0.9760 - val_loss: 4.4545 - val_acc: 0.2800\n",
      "Epoch 124/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2347 - acc: 0.9740 - val_loss: 4.4519 - val_acc: 0.2800\n",
      "Epoch 125/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2317 - acc: 0.9820 - val_loss: 4.4538 - val_acc: 0.2800\n",
      "Epoch 126/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2320 - acc: 0.9820 - val_loss: 4.4556 - val_acc: 0.2800\n",
      "Epoch 127/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2259 - acc: 0.9800 - val_loss: 4.4585 - val_acc: 0.2800\n",
      "Epoch 128/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2240 - acc: 0.9800 - val_loss: 4.4576 - val_acc: 0.2800\n",
      "Epoch 129/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2293 - acc: 0.9800 - val_loss: 4.4521 - val_acc: 0.2700\n",
      "Epoch 130/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2167 - acc: 0.9820 - val_loss: 4.4555 - val_acc: 0.2800\n",
      "Epoch 131/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2114 - acc: 0.9820 - val_loss: 4.4586 - val_acc: 0.2800\n",
      "Epoch 132/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2164 - acc: 0.9780 - val_loss: 4.4568 - val_acc: 0.2800\n",
      "Epoch 133/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2138 - acc: 0.9740 - val_loss: 4.4619 - val_acc: 0.2800\n",
      "Epoch 134/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2094 - acc: 0.9800 - val_loss: 4.4633 - val_acc: 0.2800\n",
      "Epoch 135/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2028 - acc: 0.9820 - val_loss: 4.4595 - val_acc: 0.2800\n",
      "Epoch 136/200\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.2120 - acc: 0.9780 - val_loss: 4.4619 - val_acc: 0.2800\n",
      "Epoch 137/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1994 - acc: 0.9820 - val_loss: 4.4677 - val_acc: 0.2800\n",
      "Epoch 138/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2059 - acc: 0.9780 - val_loss: 4.4732 - val_acc: 0.2800\n",
      "Epoch 139/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1953 - acc: 0.9820 - val_loss: 4.4738 - val_acc: 0.2700\n",
      "Epoch 140/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.2004 - acc: 0.9780 - val_loss: 4.4718 - val_acc: 0.2700\n",
      "Epoch 141/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1913 - acc: 0.9840 - val_loss: 4.4727 - val_acc: 0.2700\n",
      "Epoch 142/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1970 - acc: 0.9800 - val_loss: 4.4732 - val_acc: 0.2700\n",
      "Epoch 143/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1932 - acc: 0.9800 - val_loss: 4.4704 - val_acc: 0.2700\n",
      "Epoch 144/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1882 - acc: 0.9840 - val_loss: 4.4797 - val_acc: 0.2700\n",
      "Epoch 145/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1913 - acc: 0.9840 - val_loss: 4.4755 - val_acc: 0.2700\n",
      "Epoch 146/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1839 - acc: 0.9760 - val_loss: 4.4731 - val_acc: 0.2700\n",
      "Epoch 147/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1784 - acc: 0.9840 - val_loss: 4.4693 - val_acc: 0.2700\n",
      "Epoch 148/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1849 - acc: 0.9820 - val_loss: 4.4724 - val_acc: 0.2700\n",
      "Epoch 149/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1727 - acc: 0.9840 - val_loss: 4.4760 - val_acc: 0.2700\n",
      "Epoch 150/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1745 - acc: 0.9820 - val_loss: 4.4781 - val_acc: 0.2700\n",
      "Epoch 151/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1746 - acc: 0.9800 - val_loss: 4.4805 - val_acc: 0.2700\n",
      "Epoch 152/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1705 - acc: 0.9840 - val_loss: 4.4807 - val_acc: 0.2700\n",
      "Epoch 153/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1722 - acc: 0.9860 - val_loss: 4.4795 - val_acc: 0.2700\n",
      "Epoch 154/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1661 - acc: 0.9840 - val_loss: 4.4794 - val_acc: 0.2700\n",
      "Epoch 155/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1652 - acc: 0.9820 - val_loss: 4.4837 - val_acc: 0.2700\n",
      "Epoch 156/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1692 - acc: 0.9840 - val_loss: 4.4888 - val_acc: 0.2700\n",
      "Epoch 157/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1587 - acc: 0.9840 - val_loss: 4.4888 - val_acc: 0.2700\n",
      "Epoch 158/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1617 - acc: 0.9840 - val_loss: 4.4917 - val_acc: 0.2700\n",
      "Epoch 159/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1629 - acc: 0.9860 - val_loss: 4.4896 - val_acc: 0.2700\n",
      "Epoch 160/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1564 - acc: 0.9860 - val_loss: 4.4825 - val_acc: 0.2700\n",
      "Epoch 161/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1540 - acc: 0.9840 - val_loss: 4.4867 - val_acc: 0.2700\n",
      "Epoch 162/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1543 - acc: 0.9900 - val_loss: 4.4925 - val_acc: 0.2700\n",
      "Epoch 163/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1540 - acc: 0.9880 - val_loss: 4.4890 - val_acc: 0.2700\n",
      "Epoch 164/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1517 - acc: 0.9880 - val_loss: 4.4923 - val_acc: 0.2700\n",
      "Epoch 165/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1488 - acc: 0.9860 - val_loss: 4.5002 - val_acc: 0.2500\n",
      "Epoch 166/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1441 - acc: 0.9920 - val_loss: 4.4988 - val_acc: 0.2700\n",
      "Epoch 167/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1401 - acc: 0.9880 - val_loss: 4.4984 - val_acc: 0.2700\n",
      "Epoch 168/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1441 - acc: 0.9880 - val_loss: 4.5023 - val_acc: 0.2700\n",
      "Epoch 169/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1374 - acc: 0.9880 - val_loss: 4.5084 - val_acc: 0.2700\n",
      "Epoch 170/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1399 - acc: 0.9900 - val_loss: 4.5044 - val_acc: 0.2700\n",
      "Epoch 171/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1393 - acc: 0.9920 - val_loss: 4.5042 - val_acc: 0.2700\n",
      "Epoch 172/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1367 - acc: 0.9960 - val_loss: 4.5044 - val_acc: 0.2700\n",
      "Epoch 173/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1362 - acc: 0.9880 - val_loss: 4.5069 - val_acc: 0.2700\n",
      "Epoch 174/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1336 - acc: 0.9940 - val_loss: 4.5026 - val_acc: 0.2700\n",
      "Epoch 175/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1294 - acc: 0.9920 - val_loss: 4.5045 - val_acc: 0.2700\n",
      "Epoch 176/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1361 - acc: 0.9920 - val_loss: 4.5050 - val_acc: 0.2700\n",
      "Epoch 177/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1297 - acc: 0.9920 - val_loss: 4.5075 - val_acc: 0.2700\n",
      "Epoch 178/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1293 - acc: 0.9900 - val_loss: 4.5032 - val_acc: 0.2700\n",
      "Epoch 179/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1260 - acc: 0.9940 - val_loss: 4.5058 - val_acc: 0.2700\n",
      "Epoch 180/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1267 - acc: 0.9900 - val_loss: 4.5078 - val_acc: 0.2700\n",
      "Epoch 181/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1224 - acc: 0.9900 - val_loss: 4.5072 - val_acc: 0.2700\n",
      "Epoch 182/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1249 - acc: 0.9880 - val_loss: 4.5126 - val_acc: 0.2700\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1200 - acc: 0.9900 - val_loss: 4.5128 - val_acc: 0.2500\n",
      "Epoch 184/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1162 - acc: 0.9920 - val_loss: 4.5165 - val_acc: 0.2700\n",
      "Epoch 185/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1175 - acc: 0.9920 - val_loss: 4.5114 - val_acc: 0.2700\n",
      "Epoch 186/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1180 - acc: 0.9900 - val_loss: 4.5136 - val_acc: 0.2700\n",
      "Epoch 187/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1173 - acc: 0.9900 - val_loss: 4.5138 - val_acc: 0.2700\n",
      "Epoch 188/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1168 - acc: 0.9920 - val_loss: 4.5113 - val_acc: 0.2700\n",
      "Epoch 189/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1106 - acc: 0.9920 - val_loss: 4.5056 - val_acc: 0.2700\n",
      "Epoch 190/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1115 - acc: 0.9920 - val_loss: 4.5028 - val_acc: 0.2700\n",
      "Epoch 191/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1124 - acc: 0.9940 - val_loss: 4.5140 - val_acc: 0.2400\n",
      "Epoch 192/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1050 - acc: 0.9960 - val_loss: 4.5135 - val_acc: 0.2700\n",
      "Epoch 193/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1132 - acc: 0.9920 - val_loss: 4.5182 - val_acc: 0.2700\n",
      "Epoch 194/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1070 - acc: 0.9940 - val_loss: 4.5220 - val_acc: 0.2700\n",
      "Epoch 195/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1031 - acc: 0.9960 - val_loss: 4.5190 - val_acc: 0.2700\n",
      "Epoch 196/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0992 - acc: 0.9940 - val_loss: 4.5225 - val_acc: 0.2700\n",
      "Epoch 197/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0995 - acc: 0.9920 - val_loss: 4.5243 - val_acc: 0.2700\n",
      "Epoch 198/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1002 - acc: 0.9980 - val_loss: 4.5292 - val_acc: 0.2700\n",
      "Epoch 199/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0951 - acc: 0.9940 - val_loss: 4.5310 - val_acc: 0.2700\n",
      "Epoch 200/200\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0971 - acc: 0.9960 - val_loss: 4.5341 - val_acc: 0.2700\n"
     ]
    }
   ],
   "source": [
    "use_validation_split = True\n",
    "# use_validation_split = False\n",
    "\n",
    "if use_validation_split:\n",
    "    model.fit(x_train2, y_train, epochs=epochs, batch_size=batch_size, validation_split=1/6, callbacks=[TensorBoard(log_dir=config.tmp_model_dir)])\n",
    "else:    \n",
    "    model.fit(x_train2, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) Train an SVM\n",
    "This SVM requires y :: [ int ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 400\n",
    "n_classes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "[0, 4, 10, 10, 3, 6, 6, 3, 9, 18, 14, 10, 13, 13, 10, 18, 18, 17, 3, 16]\n"
     ]
    }
   ],
   "source": [
    "# convert y to [int]\n",
    "y_train3 = [y.argmax() + 1 for y in y_train[:n]]\n",
    "# exclude classes\n",
    "# y_train3 = [y.argmax() for y in y_train[:n] if (y.argmax() < n_classes and not y.argmax() in [8,2])]\n",
    "n = len(y_train3)\n",
    "print(n)\n",
    "print(y_train3[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# # SVM\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(x_train2[:n], y_train3[:n])\n",
    "# print('done')\n",
    "# result = clf.predict(x_train2[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.array([[1,2],[3,4],[1,1],[4,3]])\n",
    "# y = np.array([3,2,1,2])\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(x,y)\n",
    "# xx = np.array([[2,1]])\n",
    "# clf.predict(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name, weight_name):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(config.dataset_dir + 'models/' + model_name + '.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(config.dataset_dir + 'models/' + weight_name + '.h5', \"w\")\n",
    "    print(\"Saved model to disk\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "save_model(model, \"default_model\",\"default_model_w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_known_data = model.predict(x_train2)\n",
    "result_known_data == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954476"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = result_known_data[0].argmax()\n",
    "result_known_data[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.y_to_label_dict(dataset,result_known_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['christian']"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_, best = data.decode_y(dataset, result_known_data[0])\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8766666666666667 526 74 600\n"
     ]
    }
   ],
   "source": [
    "correct, incorrect,_,_ = data.analyse_ml_result(dataset, y_train, result_known_data)\n",
    "print(correct/float(incorrect + correct), correct, incorrect, correct+incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333 48 96 144\n"
     ]
    }
   ],
   "source": [
    "r = model.predict(models.to_vector(x_test, dataset))\n",
    "correct, incorrect,_,_ = data.analyse_ml_result(dataset, y_test, r, 1)\n",
    "print(correct/float(incorrect + correct), correct, incorrect, correct+incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2847222222222222 41 103 144\n"
     ]
    }
   ],
   "source": [
    "r = model.predict(models.to_vector(x_test, dataset))\n",
    "correct, incorrect, c, ic = data.analyse_ml_result(dataset, y_test, r, 10)\n",
    "print(correct/float(incorrect + correct), correct, incorrect, correct+incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'adventur': 1,\n",
       "         'children': 4,\n",
       "         'epistolari': 3,\n",
       "         'fantasi': 9,\n",
       "         'gothic': 2,\n",
       "         'histor': 9,\n",
       "         'horror': 1,\n",
       "         'nonfict': 2,\n",
       "         'novel': 2,\n",
       "         'novella': 1,\n",
       "         'science fiction': 3,\n",
       "         'short stori': 1,\n",
       "         'unknown': 3})"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = collections.Counter(c)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sf(string):\n",
    "    if string == 'Science Fiction':\n",
    "        string = 'SF'\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Fantasi', 9),\n",
       "             ('Histor', 9),\n",
       "             ('Children', 4),\n",
       "             ('SF', 3),\n",
       "             ('Unknown', 3),\n",
       "             ('Epistolari', 3),\n",
       "             ('Novel', 2),\n",
       "             ('Gothic', 2),\n",
       "             ('Nonfict', 2),\n",
       "             ('Novella', 1),\n",
       "             ('Short Stori', 1),\n",
       "             ('Horror', 1),\n",
       "             ('Adventur', 1)])"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amt = 30\n",
    "ls = list(counter.items())\n",
    "ls.sort(key=lambda x: x[1], reverse=True)\n",
    "names = []\n",
    "values = []\n",
    "for k,v in ls:\n",
    "        names.append(k)\n",
    "        values.append(v)\n",
    "data = {sf(k.title()):v for k,v in ls[:amt] } \n",
    "data = collections.OrderedDict(data) # override alfabetical sorting\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_path = config.dataset_dir + 'Open_Sans_Condensed/OpenSansCondensed-Light.ttf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reduce len(data)\n",
    "# amt = 60\n",
    "# # sort by value\n",
    "# ls = list(counted.items())\n",
    "# ls.sort(key=lambda x: x[1], reverse=True)\n",
    "# data = collections.OrderedDict(ls[:amt])\n",
    "\n",
    "# fig, axs = plt.subplots(1, 1, figsize=(15, 6))#, figsize=(9, 3), sharey=True)\n",
    "\n",
    "# axs.bar(range(len(data)), list(data.values()), align='center')\n",
    "# plt.xticks(range(len(data)), list(data.keys()))\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122f8e7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = [\n",
    "    'Times New Roman', 'Tahoma', 'DejaVu Sans', 'Lucida Grande', 'Verdana'\n",
    "]\n",
    "# rcParams['font'] = font_path\n",
    "\n",
    "rcParams['font.size'] = 18\n",
    "\n",
    "prop = fm.FontProperties(fname=font_path)\n",
    "# ax.set_title('This is some random font', fontproperties=prop, size=32)\n",
    "\n",
    "# data = {'apples': 10, 'oranges': 15, 'lemons': 5, 'limes': 20}\n",
    "# names = list(data.keys())\n",
    "# values = list(data.values())\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12, 3))#, figsize=(9, 3), sharey=True)\n",
    "# axs.bar(names, values)\n",
    "axs.bar(range(len(data)), list(data.values()), align='center')\n",
    "plt.xticks(range(len(data)), list(data.keys()))\n",
    "plt.xticks(rotation=90)\n",
    "plt.fontproperties = prop\n",
    "plt.savefig('../plot/correct_labels.png')\n",
    "# fig.suptitle('Categorical Plotting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
