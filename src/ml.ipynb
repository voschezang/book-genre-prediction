{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas, os, numpy as np, collections\n",
    "import config\n",
    "np.random.seed(config.seed)\n",
    "import os, sklearn, pandas, numpy as np\n",
    "from sklearn import svm\n",
    "import skimage\n",
    "from skimage import io, filters\n",
    "from utils import utils # custom functions, in local environment\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import TensorBoard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN libs\n",
    "import keras\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, Conv3D, MaxPool2D, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset :: namedtuple(\n",
      "  'info': pandas.df\n",
      "  'labels': pandas.df('filename.txt': 'genre')\n",
      "  'genres': ['genre'] # unique genres\n",
      "  'label_dataset': SubDataset\n",
      "  'sentiment_dataset': SubDataset\n",
      "  'book_sentiment_words_list': ['filename']\n",
      "\n",
      " SubDataset :: namedtuple(\n",
      "   'dict_index_to_label' = dict to convert label_index -> label_name\n",
      "   'dict_label_to_index'= dict to convert label_name -> label_index\n",
      "   'word_list' = raw word list\n",
      "\n",
      "NP - - - [0.07630829 0.77991879]\n"
     ]
    }
   ],
   "source": [
    "import data, config, tfidf, models\n",
    "from utils import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>.\n",
      "['defeated', 'angry', 'jollities', 'loyalist', 'regretfully', 'respectable', 'radiancy', 'devastator', 'sappy', 'pardons', 'failures', 'compassionate', 'dissatisfactions', 'benevolently', 'gentler', 'true', 'growth', 'agreeably', 'manipulated', 'inspiration']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['title', 'filename', 'title.1', 'author', 'release year', 'genre',\n",
       "       'pos score', 'neg score', 'neu score', 'comp score', 'amt pos',\n",
       "       'amt neg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# info = pandas.read_csv(config.dataset_dir + 'final_data.csv')\n",
    "dataset = data.init_dataset()\n",
    "dataset.info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.book_sentiment_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "amt = 600\n",
    "train = dataset.book_sentiment_words_list[:amt]\n",
    "test = dataset.book_sentiment_words_list[amt:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = data.extract_all(dataset, train)\n",
    "x_test, y_test = data.extract_all(dataset, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['christian',\n",
       " 'adventur',\n",
       " 'western',\n",
       " 'travel',\n",
       " 'comic',\n",
       " 'knstlerroman',\n",
       " 'adventur',\n",
       " 'children',\n",
       " 'satir',\n",
       " 'polit',\n",
       " 'children',\n",
       " 'children',\n",
       " 'young adult',\n",
       " 'science fiction',\n",
       " 'satir',\n",
       " 'detect',\n",
       " 'dystopian',\n",
       " 'horror',\n",
       " 'children',\n",
       " 'adventur',\n",
       " 'unknown',\n",
       " 'frame stori',\n",
       " 'histor',\n",
       " 'science',\n",
       " 'cryptozoolog',\n",
       " 'romance',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'adventur',\n",
       " 'nonsens poetri',\n",
       " 'nonfict',\n",
       " 'adventur',\n",
       " 'adventur',\n",
       " 'science fiction',\n",
       " 'science fiction',\n",
       " 'short stori',\n",
       " 'lost world genr',\n",
       " 'lost world genr',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'science fiction',\n",
       " 'literari realism',\n",
       " 'literari realism',\n",
       " 'children',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'histor',\n",
       " 'thriller',\n",
       " 'children',\n",
       " 'nonfict',\n",
       " 'fantasi',\n",
       " 'bildungsroman',\n",
       " 'nonprofit',\n",
       " 'biographi',\n",
       " 'autobiographi',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'literari realism',\n",
       " 'juvenil',\n",
       " 'novel of manner',\n",
       " 'black comedi',\n",
       " 'mysteri',\n",
       " 'science fiction',\n",
       " 'unknown',\n",
       " 'histor',\n",
       " 'romance',\n",
       " 'science fiction',\n",
       " 'mysteri',\n",
       " 'mysteri',\n",
       " 'novel',\n",
       " 'science fiction',\n",
       " 'science fiction',\n",
       " 'adventur',\n",
       " 'tragicomedi',\n",
       " 'mysteri',\n",
       " 'unknown',\n",
       " 'young adult',\n",
       " 'mysteri',\n",
       " 'thriller',\n",
       " 'detect stori',\n",
       " 'literari',\n",
       " 'histor',\n",
       " 'philosophi',\n",
       " 'gothic',\n",
       " 'selfhelp',\n",
       " 'apocalyptandpostapocalypt',\n",
       " 'satir',\n",
       " 'spi',\n",
       " 'unknown',\n",
       " 'novel',\n",
       " 'mysteri',\n",
       " 'children',\n",
       " 'travel',\n",
       " 'satir',\n",
       " 'war',\n",
       " 'war',\n",
       " 'mysteri',\n",
       " 'christian',\n",
       " 'dystopian',\n",
       " 'unknown',\n",
       " 'gothic',\n",
       " 'diariand',\n",
       " 'diariand',\n",
       " 'war',\n",
       " 'romantic',\n",
       " 'adventur',\n",
       " 'gothic',\n",
       " 'mysteri',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'novella',\n",
       " 'utopiananddystopian',\n",
       " 'bush poetri',\n",
       " 'adventur',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'horror',\n",
       " 'autobiograph',\n",
       " 'novella',\n",
       " 'detect',\n",
       " 'biograph',\n",
       " 'biographi',\n",
       " 'biographi',\n",
       " 'mysteri',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'epistolari',\n",
       " 'fantasi',\n",
       " 'children',\n",
       " 'adventur',\n",
       " 'literari realism',\n",
       " 'biographi',\n",
       " 'christian',\n",
       " 'fiction',\n",
       " 'fiction',\n",
       " 'hindi',\n",
       " 'romance',\n",
       " 'literari realism',\n",
       " 'histor',\n",
       " 'altern histori',\n",
       " 'epistolari',\n",
       " 'fantasi',\n",
       " 'unknown',\n",
       " 'bildungsroman',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'dystopia',\n",
       " 'dystopia',\n",
       " 'histor',\n",
       " 'satir',\n",
       " 'romantic',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'unknown',\n",
       " 'black comedi',\n",
       " 'black comedi',\n",
       " 'frame stori',\n",
       " 'frame stori',\n",
       " 'juvenil',\n",
       " 'children',\n",
       " 'children',\n",
       " 'children',\n",
       " 'novel',\n",
       " 'utopian',\n",
       " 'novella',\n",
       " 'detect',\n",
       " 'histor',\n",
       " 'adventur',\n",
       " 'children',\n",
       " 'fantasi',\n",
       " 'children',\n",
       " 'folklor',\n",
       " 'fantasi',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'fantasi',\n",
       " 'detect',\n",
       " 'adventur',\n",
       " 'philosophi',\n",
       " 'children',\n",
       " 'histor',\n",
       " 'unknown',\n",
       " 'fantasi',\n",
       " 'gothic',\n",
       " 'adventur',\n",
       " 'adventur',\n",
       " 'short stori',\n",
       " 'children',\n",
       " 'fantasi',\n",
       " 'gothic',\n",
       " 'unknown',\n",
       " 'adventur',\n",
       " 'nonfict',\n",
       " 'children',\n",
       " 'histor',\n",
       " 'unknown',\n",
       " 'science fiction',\n",
       " 'sensat',\n",
       " 'sensat',\n",
       " 'ruritanian romanc',\n",
       " 'natur write',\n",
       " 'poetri',\n",
       " 'histor',\n",
       " 'novel',\n",
       " 'young adult',\n",
       " 'histor',\n",
       " 'detect',\n",
       " 'horror',\n",
       " 'histor',\n",
       " 'canadian',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'science fiction',\n",
       " 'science fiction',\n",
       " 'comic',\n",
       " 'adventur',\n",
       " 'children',\n",
       " 'children',\n",
       " 'horror',\n",
       " 'children',\n",
       " 'science fiction',\n",
       " 'thriller',\n",
       " 'thriller',\n",
       " 'mysteri',\n",
       " 'mysteri',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'nonfict',\n",
       " 'science fiction',\n",
       " 'syair',\n",
       " 'crime',\n",
       " 'textbook',\n",
       " 'textbook',\n",
       " 'thriller',\n",
       " 'histor',\n",
       " 'fantasi',\n",
       " 'polit',\n",
       " 'interior design',\n",
       " 'histor',\n",
       " 'young adult',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'temper movement',\n",
       " 'temper movement',\n",
       " 'horror',\n",
       " 'philosophi',\n",
       " 'essay',\n",
       " 'short stori',\n",
       " 'short stori',\n",
       " 'roman clef',\n",
       " 'young adult',\n",
       " 'young adult',\n",
       " 'young adult',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'horror',\n",
       " 'children',\n",
       " 'children',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'travel',\n",
       " 'travel',\n",
       " 'fantasi',\n",
       " 'cookbook',\n",
       " 'cookbook',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'biographi',\n",
       " 'biographi',\n",
       " 'science fiction',\n",
       " 'science fiction',\n",
       " 'unknown',\n",
       " 'science fiction',\n",
       " 'adventur',\n",
       " 'pictur book',\n",
       " 'pictur book',\n",
       " 'young adult',\n",
       " 'thriller',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'novella',\n",
       " 'histori of idea',\n",
       " 'refer work',\n",
       " 'refer work',\n",
       " 'fantasi',\n",
       " 'polit',\n",
       " 'polit',\n",
       " 'christian',\n",
       " 'christian',\n",
       " 'children',\n",
       " 'science fiction',\n",
       " 'nonfict',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'science fiction',\n",
       " 'science fiction',\n",
       " 'gothic',\n",
       " 'autobiograph',\n",
       " 'autobiograph',\n",
       " 'autobiograph',\n",
       " 'adventur',\n",
       " 'adventur',\n",
       " 'histor',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'fiction',\n",
       " 'fantasi',\n",
       " 'sword and sorceri',\n",
       " 'sword and sorceri',\n",
       " 'children',\n",
       " 'children',\n",
       " 'sword and sorceri',\n",
       " 'sword and sorceri',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'detect',\n",
       " 'comedi',\n",
       " 'comedi',\n",
       " 'horror',\n",
       " 'gothic',\n",
       " 'autobiographi',\n",
       " 'biographi',\n",
       " 'detect',\n",
       " 'detect',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'children',\n",
       " 'children',\n",
       " 'children',\n",
       " 'crime',\n",
       " 'detect',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'science fiction',\n",
       " 'fantasi',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'nonfict',\n",
       " 'nonfict',\n",
       " 'encyclopedia',\n",
       " 'novella',\n",
       " 'novel',\n",
       " 'science fiction',\n",
       " 'western',\n",
       " 'western',\n",
       " 'detect',\n",
       " 'biograph',\n",
       " 'novel',\n",
       " 'children',\n",
       " 'nonfict',\n",
       " 'young adult',\n",
       " 'young adult',\n",
       " 'bildungsroman',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'children',\n",
       " 'fantasi',\n",
       " 'children',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'polit',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'science fiction',\n",
       " 'science fiction',\n",
       " 'science fiction',\n",
       " 'science fiction',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'bildungsroman',\n",
       " 'fantasi',\n",
       " 'utopiananddystopian',\n",
       " 'utopiananddystopian',\n",
       " 'poetri',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'science fiction',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'novel',\n",
       " 'crime',\n",
       " 'children',\n",
       " 'children',\n",
       " 'romantic',\n",
       " 'detect',\n",
       " 'detect',\n",
       " 'nonprofit',\n",
       " 'polit',\n",
       " 'polit',\n",
       " 'polit',\n",
       " 'bildungsroman',\n",
       " 'bildungsroman',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'philosophi',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'christian',\n",
       " 'fiction',\n",
       " 'prose poetri',\n",
       " 'prose poetri',\n",
       " 'biographi',\n",
       " 'biographi',\n",
       " 'nonfict',\n",
       " 'fantasi',\n",
       " 'western',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'memoir',\n",
       " 'memoir',\n",
       " 'biographi',\n",
       " 'biographi',\n",
       " 'young adult',\n",
       " 'young adult',\n",
       " 'slave narr',\n",
       " 'slave narr',\n",
       " 'detect',\n",
       " 'detect',\n",
       " 'histor',\n",
       " 'horror',\n",
       " 'novella',\n",
       " 'novella',\n",
       " 'young adult',\n",
       " 'humor',\n",
       " 'war',\n",
       " 'war',\n",
       " 'feministscienc',\n",
       " 'science fiction',\n",
       " 'philosophi',\n",
       " 'histor',\n",
       " 'detect',\n",
       " 'fiction',\n",
       " 'adventur',\n",
       " 'travel',\n",
       " 'children',\n",
       " 'science fiction',\n",
       " 'militari histori',\n",
       " 'militari histori',\n",
       " 'histor',\n",
       " 'philosophi',\n",
       " 'histor',\n",
       " 'children',\n",
       " 'young adult',\n",
       " 'adventur',\n",
       " 'thriller',\n",
       " 'adventur',\n",
       " 'philosophi',\n",
       " 'satir',\n",
       " 'satir',\n",
       " 'horror',\n",
       " 'romance',\n",
       " 'bildungsroman',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'short stori',\n",
       " 'children',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'adventur',\n",
       " 'horror',\n",
       " 'social commentari',\n",
       " 'social commentari',\n",
       " 'children',\n",
       " 'short stori',\n",
       " 'short stori',\n",
       " 'romance',\n",
       " 'children',\n",
       " 'children',\n",
       " 'photographi',\n",
       " 'romance',\n",
       " 'unknown',\n",
       " 'children',\n",
       " 'lost world genr',\n",
       " 'unknown',\n",
       " 'thriller',\n",
       " 'thriller',\n",
       " 'fiction',\n",
       " 'christian',\n",
       " 'psycholog',\n",
       " 'science fiction',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'nonfict',\n",
       " 'travel',\n",
       " 'travel',\n",
       " 'travel',\n",
       " 'travel',\n",
       " 'travel',\n",
       " 'travel',\n",
       " 'travel',\n",
       " 'travel',\n",
       " 'travel',\n",
       " 'travel',\n",
       " 'novel',\n",
       " 'adventur',\n",
       " 'mysteri',\n",
       " 'mysteri',\n",
       " 'children',\n",
       " 'unknown',\n",
       " 'adventur',\n",
       " 'histor',\n",
       " 'histor',\n",
       " 'busi',\n",
       " 'histor',\n",
       " 'gaucho',\n",
       " 'fantasi',\n",
       " 'fantasi',\n",
       " 'mysteri',\n",
       " 'adventur',\n",
       " 'romance',\n",
       " 'thriller',\n",
       " 'science fiction',\n",
       " 'travel write',\n",
       " 'travel write',\n",
       " 'planetari romanc',\n",
       " 'histor',\n",
       " 'short stori',\n",
       " 'monograph',\n",
       " 'unknown',\n",
       " 'short stori',\n",
       " 'short stori',\n",
       " 'nonfict',\n",
       " 'theodici',\n",
       " 'spiritu autobiographi',\n",
       " 'thriller',\n",
       " 'thriller',\n",
       " 'contemporari romanc',\n",
       " 'autobiograph',\n",
       " 'autobiograph',\n",
       " 'fantasi',\n",
       " 'unknown',\n",
       " 'comic',\n",
       " 'science fiction',\n",
       " 'comic',\n",
       " 'horror',\n",
       " 'comedi',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'novel',\n",
       " 'fantasi',\n",
       " 'unknown',\n",
       " 'crime',\n",
       " 'fantasi',\n",
       " 'romance',\n",
       " 'romance',\n",
       " 'adventur',\n",
       " 'novel',\n",
       " 'adventur',\n",
       " 'adventur',\n",
       " 'adventur',\n",
       " 'adventur',\n",
       " 'unknown',\n",
       " 'biographi',\n",
       " 'war',\n",
       " 'comedi',\n",
       " 'comedi',\n",
       " 'western',\n",
       " 'nonfict',\n",
       " 'nonfict']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the labels\n",
    "\n",
    "Encode the labels to one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test = data.labels_to_vectors(dataset.label_dataset,y_train, y_test)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert tokenlist to vectors\n",
    "\n",
    "### Using sentiment-wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dataset.sentiment_dataset\n",
    "a = 'a s d fp sks dk fsji sdf'.split(' ')\n",
    "data.tokenlist_to_vector(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using polarization scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05957593, 0.04597156, 0.66307096, 0.02651661])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.polarization_scores_to_vector(dataset,'706.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NER scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "Although most of the input consists of classes, many classes will be correlated (e.g. related genres).\n",
    "Therefore a neural network is chosen to model the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 5095)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2 = models.to_vector(x_train, dataset)\n",
    "x_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 (5095,)\n",
      "output length 113\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(x_train2) # = length of the list of images (matrices)\n",
    "input_shape = x_train2.shape[1:] # = shape of an individual image (matrix)\n",
    "output_length = (y_train[0]).shape[0] # = length of an individual label\n",
    "print(n_samples, input_shape)\n",
    "print('output length', output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               1304576   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 113)               29041     \n",
      "=================================================================\n",
      "Total params: 1,333,617\n",
      "Trainable params: 1,333,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import models # src/models.py\n",
    "dropout = 0.20\n",
    "# model, summary = models.sequential(input_shape, output_length, dropout)\n",
    "def sequential(input_shape, output_length, dropout=0.10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu', input_shape=input_shape))\n",
    "    #model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(output_length, activation='softmax'))\n",
    "    # in addition, return a function that displays information about the model\n",
    "    return model, model.summary\n",
    "\n",
    "model, summary = sequential(input_shape, output_length, dropout)\n",
    "\n",
    "summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "- Categorical cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a batch size\n",
    "batch_size = round(16)\n",
    "# n epochs = n iterations over all the training data\n",
    "epochs = 220"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "### Show logs [here](http://localhost:6006/#scalars)\n",
    "\n",
    "When training a new model, close any _Tenserboard_ tab,\n",
    "\n",
    "then run ` make logs ` and start training.\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/220\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 4.6978 - acc: 0.0633\n",
      "Epoch 2/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 4.6208 - acc: 0.0900\n",
      "Epoch 3/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 4.5101 - acc: 0.1067\n",
      "Epoch 4/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 4.3685 - acc: 0.0967\n",
      "Epoch 5/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 4.2175 - acc: 0.1033\n",
      "Epoch 6/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 4.0894 - acc: 0.1183\n",
      "Epoch 7/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.9844 - acc: 0.1000\n",
      "Epoch 8/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.9151 - acc: 0.1150\n",
      "Epoch 9/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.8580 - acc: 0.1250\n",
      "Epoch 10/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.8298 - acc: 0.1433\n",
      "Epoch 11/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.7982 - acc: 0.1517\n",
      "Epoch 12/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.7678 - acc: 0.1550\n",
      "Epoch 13/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.7261 - acc: 0.1683\n",
      "Epoch 14/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.7136 - acc: 0.1733\n",
      "Epoch 15/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.6808 - acc: 0.1733\n",
      "Epoch 16/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.6614 - acc: 0.1983\n",
      "Epoch 17/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.6343 - acc: 0.2117\n",
      "Epoch 18/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.6268 - acc: 0.2033\n",
      "Epoch 19/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.6022 - acc: 0.2117\n",
      "Epoch 20/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.5840 - acc: 0.2183\n",
      "Epoch 21/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.5605 - acc: 0.2450\n",
      "Epoch 22/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.5213 - acc: 0.2450\n",
      "Epoch 23/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.5134 - acc: 0.2400\n",
      "Epoch 24/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.4898 - acc: 0.2400\n",
      "Epoch 25/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.4750 - acc: 0.2650\n",
      "Epoch 26/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.4425 - acc: 0.2817\n",
      "Epoch 27/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.4231 - acc: 0.2583\n",
      "Epoch 28/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.4071 - acc: 0.2867\n",
      "Epoch 29/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.3932 - acc: 0.2733\n",
      "Epoch 30/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.3755 - acc: 0.2867\n",
      "Epoch 31/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.3418 - acc: 0.3033\n",
      "Epoch 32/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.3329 - acc: 0.3100\n",
      "Epoch 33/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.3119 - acc: 0.3233\n",
      "Epoch 34/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.2767 - acc: 0.3250\n",
      "Epoch 35/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.2667 - acc: 0.3083\n",
      "Epoch 36/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.2334 - acc: 0.3100\n",
      "Epoch 37/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.2199 - acc: 0.3233\n",
      "Epoch 38/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.1974 - acc: 0.3133\n",
      "Epoch 39/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.1722 - acc: 0.3317\n",
      "Epoch 40/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.1533 - acc: 0.3483\n",
      "Epoch 41/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.1339 - acc: 0.3367\n",
      "Epoch 42/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.1042 - acc: 0.3367\n",
      "Epoch 43/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.0995 - acc: 0.3300\n",
      "Epoch 44/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.0783 - acc: 0.3550\n",
      "Epoch 45/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.0554 - acc: 0.3617\n",
      "Epoch 46/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.0359 - acc: 0.3617\n",
      "Epoch 47/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 3.0048 - acc: 0.3633\n",
      "Epoch 48/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.9941 - acc: 0.3633\n",
      "Epoch 49/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.9724 - acc: 0.3783\n",
      "Epoch 50/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.9545 - acc: 0.3817\n",
      "Epoch 51/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.9163 - acc: 0.3950\n",
      "Epoch 52/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.9104 - acc: 0.3967\n",
      "Epoch 53/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.8862 - acc: 0.3833\n",
      "Epoch 54/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.8598 - acc: 0.4000\n",
      "Epoch 55/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.8342 - acc: 0.3950\n",
      "Epoch 56/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.8243 - acc: 0.4100\n",
      "Epoch 57/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.8020 - acc: 0.4183\n",
      "Epoch 58/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.7848 - acc: 0.4083\n",
      "Epoch 59/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.7557 - acc: 0.4250\n",
      "Epoch 60/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.7357 - acc: 0.4167\n",
      "Epoch 61/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.7149 - acc: 0.4283\n",
      "Epoch 62/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.6898 - acc: 0.4167\n",
      "Epoch 63/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.6877 - acc: 0.4333\n",
      "Epoch 64/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.6576 - acc: 0.4333\n",
      "Epoch 65/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.6456 - acc: 0.4483\n",
      "Epoch 66/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.6084 - acc: 0.4567\n",
      "Epoch 67/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.6075 - acc: 0.4533\n",
      "Epoch 68/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.5743 - acc: 0.4533\n",
      "Epoch 69/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.5713 - acc: 0.4517\n",
      "Epoch 70/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.5440 - acc: 0.4817\n",
      "Epoch 71/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.5173 - acc: 0.4833\n",
      "Epoch 72/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.5084 - acc: 0.4733\n",
      "Epoch 73/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.4709 - acc: 0.5017\n",
      "Epoch 74/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.4569 - acc: 0.4933\n",
      "Epoch 75/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.4541 - acc: 0.4750\n",
      "Epoch 76/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.4183 - acc: 0.5067\n",
      "Epoch 77/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.3966 - acc: 0.5117\n",
      "Epoch 78/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.3750 - acc: 0.5133\n",
      "Epoch 79/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.3600 - acc: 0.5317\n",
      "Epoch 80/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.3352 - acc: 0.5250\n",
      "Epoch 81/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.3271 - acc: 0.5233\n",
      "Epoch 82/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.3057 - acc: 0.5267\n",
      "Epoch 83/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.2913 - acc: 0.5317\n",
      "Epoch 84/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.2731 - acc: 0.5417\n",
      "Epoch 85/220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 2ms/step - loss: 2.2595 - acc: 0.5450\n",
      "Epoch 86/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.2343 - acc: 0.5667\n",
      "Epoch 87/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.2120 - acc: 0.5583\n",
      "Epoch 88/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.1935 - acc: 0.5750\n",
      "Epoch 89/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.1793 - acc: 0.5850\n",
      "Epoch 90/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.1579 - acc: 0.5817\n",
      "Epoch 91/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.1466 - acc: 0.5800\n",
      "Epoch 92/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.1145 - acc: 0.5817\n",
      "Epoch 93/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.1002 - acc: 0.5817\n",
      "Epoch 94/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.0939 - acc: 0.5933\n",
      "Epoch 95/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.0744 - acc: 0.6033A: 0s - loss: 2.1352 - acc\n",
      "Epoch 96/220\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.0524 - acc: 0.6067\n",
      "Epoch 97/220\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.0544 - acc: 0.6100\n",
      "Epoch 98/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.0258 - acc: 0.6183\n",
      "Epoch 99/220\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 2.0024 - acc: 0.6183\n",
      "Epoch 100/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.9935 - acc: 0.6117\n",
      "Epoch 101/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.9709 - acc: 0.6150\n",
      "Epoch 102/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.9435 - acc: 0.6217\n",
      "Epoch 103/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.9414 - acc: 0.6283\n",
      "Epoch 104/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.9228 - acc: 0.6400\n",
      "Epoch 105/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.8941 - acc: 0.6400\n",
      "Epoch 106/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.8781 - acc: 0.6433\n",
      "Epoch 107/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.8637 - acc: 0.6517\n",
      "Epoch 108/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.8558 - acc: 0.6367\n",
      "Epoch 109/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.8321 - acc: 0.6433\n",
      "Epoch 110/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.8204 - acc: 0.6583\n",
      "Epoch 111/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.8202 - acc: 0.6533\n",
      "Epoch 112/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.7941 - acc: 0.6733\n",
      "Epoch 113/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.7691 - acc: 0.6817\n",
      "Epoch 114/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.7625 - acc: 0.6650\n",
      "Epoch 115/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.7459 - acc: 0.6767\n",
      "Epoch 116/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.7297 - acc: 0.6883\n",
      "Epoch 117/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.6927 - acc: 0.6867\n",
      "Epoch 118/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.6912 - acc: 0.7000\n",
      "Epoch 119/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.6732 - acc: 0.7017\n",
      "Epoch 120/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.6604 - acc: 0.7067\n",
      "Epoch 121/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.6459 - acc: 0.6983\n",
      "Epoch 122/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.6353 - acc: 0.6967\n",
      "Epoch 123/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.6132 - acc: 0.7217\n",
      "Epoch 124/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.6057 - acc: 0.7167\n",
      "Epoch 125/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.5922 - acc: 0.7200\n",
      "Epoch 126/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.5748 - acc: 0.7333\n",
      "Epoch 127/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.5550 - acc: 0.7233\n",
      "Epoch 128/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.5551 - acc: 0.7333\n",
      "Epoch 129/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.5360 - acc: 0.7317\n",
      "Epoch 130/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.5106 - acc: 0.7333\n",
      "Epoch 131/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.5210 - acc: 0.7333\n",
      "Epoch 132/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.4933 - acc: 0.7317\n",
      "Epoch 133/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.4815 - acc: 0.7317\n",
      "Epoch 134/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.4585 - acc: 0.7400\n",
      "Epoch 135/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.4465 - acc: 0.7533\n",
      "Epoch 136/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.4427 - acc: 0.7450\n",
      "Epoch 137/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.4155 - acc: 0.7633\n",
      "Epoch 138/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.4075 - acc: 0.7533\n",
      "Epoch 139/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.3889 - acc: 0.7567\n",
      "Epoch 140/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.3898 - acc: 0.7600\n",
      "Epoch 141/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.3678 - acc: 0.7567\n",
      "Epoch 142/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.3502 - acc: 0.7717\n",
      "Epoch 143/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.3330 - acc: 0.7783\n",
      "Epoch 144/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.3294 - acc: 0.7750\n",
      "Epoch 145/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.3048 - acc: 0.7733\n",
      "Epoch 146/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.3023 - acc: 0.7783\n",
      "Epoch 147/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.2925 - acc: 0.7833\n",
      "Epoch 148/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.2834 - acc: 0.7900\n",
      "Epoch 149/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.2531 - acc: 0.7967\n",
      "Epoch 150/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.2468 - acc: 0.7900\n",
      "Epoch 151/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.2439 - acc: 0.7917\n",
      "Epoch 152/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.2330 - acc: 0.7933\n",
      "Epoch 153/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.2250 - acc: 0.7933\n",
      "Epoch 154/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.1882 - acc: 0.7950\n",
      "Epoch 155/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.1889 - acc: 0.8100\n",
      "Epoch 156/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.1871 - acc: 0.8050\n",
      "Epoch 157/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.1812 - acc: 0.8083\n",
      "Epoch 158/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.1698 - acc: 0.8083\n",
      "Epoch 159/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.1482 - acc: 0.8167\n",
      "Epoch 160/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.1360 - acc: 0.8200\n",
      "Epoch 161/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.1227 - acc: 0.8250\n",
      "Epoch 162/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.1124 - acc: 0.8167\n",
      "Epoch 163/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0976 - acc: 0.8300\n",
      "Epoch 164/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0825 - acc: 0.8200\n",
      "Epoch 165/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0694 - acc: 0.8267\n",
      "Epoch 166/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0788 - acc: 0.8283\n",
      "Epoch 167/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0574 - acc: 0.8317\n",
      "Epoch 168/220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0349 - acc: 0.8350\n",
      "Epoch 169/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0409 - acc: 0.8417\n",
      "Epoch 170/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0168 - acc: 0.8467\n",
      "Epoch 171/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0199 - acc: 0.8467\n",
      "Epoch 172/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0084 - acc: 0.8383\n",
      "Epoch 173/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.9871 - acc: 0.8550\n",
      "Epoch 174/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.9859 - acc: 0.8517\n",
      "Epoch 175/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.9609 - acc: 0.8683\n",
      "Epoch 176/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.9696 - acc: 0.8550\n",
      "Epoch 177/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.9571 - acc: 0.8567\n",
      "Epoch 178/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.9207 - acc: 0.8650\n",
      "Epoch 179/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.9351 - acc: 0.8583\n",
      "Epoch 180/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.9158 - acc: 0.8667\n",
      "Epoch 181/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.9101 - acc: 0.8650\n",
      "Epoch 182/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.8996 - acc: 0.8717\n",
      "Epoch 183/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.8845 - acc: 0.8683\n",
      "Epoch 184/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.8795 - acc: 0.8833\n",
      "Epoch 185/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.8691 - acc: 0.8767\n",
      "Epoch 186/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.8561 - acc: 0.8833\n",
      "Epoch 187/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.8475 - acc: 0.8833\n",
      "Epoch 188/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.8463 - acc: 0.8850\n",
      "Epoch 189/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.8294 - acc: 0.8850\n",
      "Epoch 190/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.8096 - acc: 0.8967\n",
      "Epoch 191/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.8174 - acc: 0.8850\n",
      "Epoch 192/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.8061 - acc: 0.8967\n",
      "Epoch 193/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.7993 - acc: 0.8883\n",
      "Epoch 194/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.7779 - acc: 0.8900\n",
      "Epoch 195/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.7939 - acc: 0.8900\n",
      "Epoch 196/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.7665 - acc: 0.8983\n",
      "Epoch 197/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.7543 - acc: 0.8817\n",
      "Epoch 198/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.7475 - acc: 0.8933\n",
      "Epoch 199/220\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.7458 - acc: 0.8967\n",
      "Epoch 200/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.7394 - acc: 0.8983\n",
      "Epoch 201/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.7391 - acc: 0.9083\n",
      "Epoch 202/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.7208 - acc: 0.9067\n",
      "Epoch 203/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.7122 - acc: 0.9067\n",
      "Epoch 204/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.7012 - acc: 0.9017\n",
      "Epoch 205/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6940 - acc: 0.9133\n",
      "Epoch 206/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6845 - acc: 0.9133\n",
      "Epoch 207/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6859 - acc: 0.9217\n",
      "Epoch 208/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6662 - acc: 0.9117\n",
      "Epoch 209/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6672 - acc: 0.9167\n",
      "Epoch 210/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6543 - acc: 0.9250A: 1s - loss: 0.57\n",
      "Epoch 211/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6482 - acc: 0.9167\n",
      "Epoch 212/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6368 - acc: 0.9267\n",
      "Epoch 213/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6252 - acc: 0.9167\n",
      "Epoch 214/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6231 - acc: 0.9233\n",
      "Epoch 215/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6075 - acc: 0.9233\n",
      "Epoch 216/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6055 - acc: 0.9283\n",
      "Epoch 217/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5936 - acc: 0.9283\n",
      "Epoch 218/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.6006 - acc: 0.9250\n",
      "Epoch 219/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5949 - acc: 0.9333\n",
      "Epoch 220/220\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.5791 - acc: 0.9350\n"
     ]
    }
   ],
   "source": [
    "use_validation_split = True\n",
    "use_validation_split = False\n",
    "\n",
    "if use_validation_split:\n",
    "    model.fit(x_train2, y_train, epochs=epochs, batch_size=batch_size, validation_split=1/6, callbacks=[TensorBoard(log_dir=config.tmp_model_dir)])\n",
    "else:    \n",
    "    model.fit(x_train2, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) Train an SVM\n",
    "This SVM requires y :: [ int ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 400\n",
    "n_classes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "[17, 1, 110, 102, 19, 52, 1, 15, 83, 75, 15, 15, 113, 85, 83, 25, 30, 48, 15, 1]\n"
     ]
    }
   ],
   "source": [
    "# convert y to [int]\n",
    "y_train3 = [y.argmax() + 1 for y in y_train[:n]]\n",
    "# exclude classes\n",
    "# y_train3 = [y.argmax() for y in y_train[:n] if (y.argmax() < n_classes and not y.argmax() in [8,2])]\n",
    "n = len(y_train3)\n",
    "print(n)\n",
    "print(y_train3[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SVM\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(x_train2[:n], y_train3[:n])\n",
    "# print('done')\n",
    "# result = clf.predict(x_train2[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.array([[1,2],[3,4],[1,1],[4,3]])\n",
    "# y = np.array([3,2,1,2])\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(x,y)\n",
    "# xx = np.array([[2,1]])\n",
    "# clf.predict(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name, weight_name):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(config.dataset_dir + 'models/' + model_name + '.json', \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(config.dataset_dir + 'models/' + weight_name + '.h5', \"w\")\n",
    "    print(\"Saved model to disk\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "save_model(model, \"default_model\",\"default_model_w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_known_data = model.predict(x_train2)\n",
    "result_known_data == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5535803"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = result_known_data[0].argmax()\n",
    "result_known_data[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.y_to_label_dict(dataset,result_known_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['christian']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_, best = data.decode_y(dataset, result_known_data[0])\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9433333333333334 566 34 600\n"
     ]
    }
   ],
   "source": [
    "correct, incorrect,_,_ = data.analyse_ml_result(dataset, y_train, result_known_data)\n",
    "print(correct/float(incorrect + correct), correct, incorrect, correct+incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3611111111111111 52 92 144\n"
     ]
    }
   ],
   "source": [
    "r = model.predict(models.to_vector(x_test, dataset))\n",
    "correct, incorrect,_,_ = data.analyse_ml_result(dataset, y_test, r, 1)\n",
    "print(correct/float(incorrect + correct), correct, incorrect, correct+incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5486111111111112 79 65 144\n"
     ]
    }
   ],
   "source": [
    "r = model.predict(models.to_vector(x_test, dataset))\n",
    "correct, incorrect, c, ic = data.analyse_ml_result(dataset, y_test, r, 5)\n",
    "print(correct/float(incorrect + correct), correct, incorrect, correct+incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'adventur': 6,\n",
       "         'children': 16,\n",
       "         'detect': 2,\n",
       "         'epistolari': 2,\n",
       "         'fantasi': 17,\n",
       "         'fiction': 2,\n",
       "         'gothic': 2,\n",
       "         'histor': 13,\n",
       "         'horror': 3,\n",
       "         'nonfict': 2,\n",
       "         'novel': 10,\n",
       "         'novella': 1,\n",
       "         'science fiction': 4,\n",
       "         'short stori': 1,\n",
       "         'unknown': 12})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = collections.Counter(c)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sf(string):\n",
    "    if string == 'Science Fiction':\n",
    "        string = 'SF'\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Fantasi', 17),\n",
       "             ('Children', 16),\n",
       "             ('Histor', 13),\n",
       "             ('Unknown', 12),\n",
       "             ('Novel', 10),\n",
       "             ('Adventur', 6),\n",
       "             ('SF', 4),\n",
       "             ('Horror', 3),\n",
       "             ('Gothic', 2),\n",
       "             ('Detect', 2),\n",
       "             ('Nonfict', 2),\n",
       "             ('Fiction', 2),\n",
       "             ('Epistolari', 2),\n",
       "             ('Novella', 1),\n",
       "             ('Short Stori', 1)])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amt = 30\n",
    "ls = list(counter.items())\n",
    "ls.sort(key=lambda x: x[1], reverse=True)\n",
    "names = []\n",
    "values = []\n",
    "for k,v in ls:\n",
    "        names.append(k)\n",
    "        values.append(v)\n",
    "data = {sf(k.title()):v for k,v in ls[:amt] } \n",
    "data = collections.OrderedDict(data) # override alfabetical sorting\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_path = config.dataset_dir + 'Open_Sans_Condensed/OpenSansCondensed-Light.ttf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reduce len(data)\n",
    "# amt = 60\n",
    "# # sort by value\n",
    "# ls = list(counted.items())\n",
    "# ls.sort(key=lambda x: x[1], reverse=True)\n",
    "# data = collections.OrderedDict(ls[:amt])\n",
    "\n",
    "# fig, axs = plt.subplots(1, 1, figsize=(15, 6))#, figsize=(9, 3), sharey=True)\n",
    "\n",
    "# axs.bar(range(len(data)), list(data.values()), align='center')\n",
    "# plt.xticks(range(len(data)), list(data.keys()))\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129581b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = [\n",
    "    'Times New Roman', 'Tahoma', 'DejaVu Sans', 'Lucida Grande', 'Verdana'\n",
    "]\n",
    "# rcParams['font'] = font_path\n",
    "\n",
    "rcParams['font.size'] = 18\n",
    "\n",
    "prop = fm.FontProperties(fname=font_path)\n",
    "# ax.set_title('This is some random font', fontproperties=prop, size=32)\n",
    "\n",
    "# data = {'apples': 10, 'oranges': 15, 'lemons': 5, 'limes': 20}\n",
    "# names = list(data.keys())\n",
    "# values = list(data.values())\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12, 3))#, figsize=(9, 3), sharey=True)\n",
    "# axs.bar(names, values)\n",
    "axs.bar(range(len(data)), list(data.values()), align='center')\n",
    "plt.xticks(range(len(data)), list(data.keys()))\n",
    "plt.xticks(rotation=90)\n",
    "plt.fontproperties = prop\n",
    "plt.savefig('../plot/correct_labels.png')\n",
    "# fig.suptitle('Categorical Plotting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
